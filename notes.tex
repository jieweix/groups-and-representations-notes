\documentclass{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[british]{babel}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{luatex85}
\usepackage[all]{xy}
\usepackage{color}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{float}
\usepackage{tikz}
\usetikzlibrary{decorations.pathreplacing}
\newcommand{\tikznode}[3][inner sep=0pt]{\tikz[remember
picture,baseline=(#2.base)]{\node(#2)[#1]{$#3$};}}
\usepackage{ytableau}
\usepackage[math]{iwona}
\usepackage{cmbright}

\renewcommand{\familydefault}{\sfdefault}

\geometry{a4paper,left=2cm,right=2cm,top=2cm,bottom=2cm}
\ytableausetup{smalltableaux}

\makeatletter
\renewcommand*\env@matrix[1][*\c@MaxMatrixCols c]{%
  \hskip -\arraycolsep
  \let\@ifnextchar\new@ifnextchar
  \array{#1}}
\makeatother
\makeatletter
\DeclareRobustCommand{\pns}{\mathrel{\text{$\m@th\proper@ideal$}}}
\newcommand{\proper@ideal}{%
  \ooalign{$\lneq$\cr\raise.22ex\hbox{$\lhd$}\cr}%
}
\makeatother

\SelectTips{eu}{}
\setlength{\fboxsep}{0pt}
\setlength\parskip{0.3em}
\setlength{\parindent}{0 pt}

\newcommand{\mult}{\text{mult}}
\newcommand{\Char}{\text{char}\,}
\newcommand{\tr}{\text{tr}}
\newcommand{\sgn}{\text{sgn}}
\newcommand{\la}{\left\langle}
\newcommand{\ra}{\right\rangle}
\newcommand{\cH}{\mathcal{H}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\linspan}{\text{linspan}}
\newcommand{\Cl}{\text{Cl}}
\newcommand{\sh}{\text{sh}}
\newcommand{\reg}{\text{reg}}
\newcommand{\End}{\text{End}}
\newcommand{\Hom}{\text{Hom}}
\newcommand{\Dic}{\text{Dic}}
\newcommand{\Aut}{\text{Aut}}
\newcommand{\Syl}{\text{Syl}}
\newcommand{\orb}{\text{orb}}
\newcommand{\ord}{\text{ord}}
\newcommand{\stab}{\text{stab}}
\newcommand{\fix}{\text{fix}}
\newcommand{\Sym}{\text{Sym}}
\newcommand{\Alt}{\text{Alt}}
\newcommand{\supp}{\text{supp}}
\newcommand{\adj}{\text{adj}\,}
\newcommand{\lcm}{\text{lcm}\,}
\newcommand{\id}{\text{id}}
\newcommand{\im}{\text{im\,}}
\newcommand{\spanset}{\text{span}}
\newcommand{\rank}{\text{rank}\,}
\newcommand{\Mod}{\text{Mod-}}

\theoremstyle{definition}

\newtheorem{defn}{Definition}[subsection]
\newtheorem{prop}[defn]{Proposition}
\newtheorem{thm}[defn]{Theorem}
\newtheorem{lemma}[defn]{Lemma}
\newtheorem{coro}[defn]{Corollary}
\newtheorem{example}[defn]{Example}
\newtheorem{exe}[defn]{Exercise}
\newtheorem{claim}[defn]{Claim}
\newtheorem*{remark}{Remark}
\newtheorem*{notation}{Notation}

\title{MA3E1 Groups and representations :: Lecture notes}
\author{Lecturer: Christian Ikenmeyer}
\date{Last edited: \today}

\begin{document}

\maketitle
\thispagestyle{empty}

\tableofcontents
\thispagestyle{empty}
\newpage
\setcounter{page}{1}

\begin{flushright}
\textit{Week 1, lecture 1 starts here}
\end{flushright}

\section{Reminders}
\begin{defn}
A \textit{group} is ...
\end{defn}

\begin{example}
\begin{itemize}
\item $\Z$ with addition
\item $\C^\times$ with multiplication
\item A subgroup of above: $\{g\in\C:g^n=1\}$, the $n$th roots of unity $\zeta_n^i$ with $\zeta_n=e^{\frac{2\pi i}{n}}$. $\zeta_n^j$ is primitive if $\ord(\zeta_n^j)=n$
\item General linear group $GL_d(K)$
\item A subgroup of above: special linear group $SL_d(K)$
\end{itemize}
\end{example}

Given $G$ and $g\in G$, one can define the \textit{cyclic} group generated by $g$, denoted $\la g\ra$, an abelian subgroup of $G$, of order $\ord(g)$.

Recall \textit{symmetric} group $S_n$ and cycle notation; verify that $|S_n|=n!$; recall elements of $S_n$ can be written as either even or odd number of transpositions (cycles of length 2) but not both, and \textit{alternating} group $A_n$, a subgroup of $S_n$.

\subsection{Group action}

\begin{defn}
Let $G$ be a group and $X$ a set. A \textit{left action} of $G$ on $X$ is a map $G\times X\rightarrow X:(g,x)\mapsto g\ast x$ which satisfies
\begin{enumerate}
\item $1_G\ast x=x \ \forall x\in X$
\item $(gh)\ast x=g\ast(h\ast x) \ \forall g,h\in G,x\in X$
\end{enumerate}
\end{defn}

\begin{example}
\label{example:gpact}
\begin{itemize}
\item $X=\{1,\ldots,n\},\ G=S_n,\ \pi\ast i:=\pi(i)$
\item $X=\R^n,\ G=GL_n(\R),\ A\ast v:=Av$
\end{itemize}
\end{example}

\begin{defn}
For $x,y\in X$, write $x\sim y$ if $\exists g\in G:g\ast x=y$. This is an equivalence relation and an equivalence class of $\sim$ is an \textit{orbit}.
\end{defn}

\begin{example}
$\orb_{GL_n(\R)}((1,0,\ldots,0))=\mathbb R_n\backslash\{0\}$ and $\orb_{GL_n(\R)}(0)=\{0\}$, so there are exactly two orbits of \ref{example:gpact}.2.
\end{example}

\begin{flushright}
\textit{Week 1, lecture 2 starts here}
\end{flushright}

\begin{defn}
$G$ acts \textit{transitively} on $X$ if there is only one orbit.
\end{defn}
e.g. \ref{example:gpact}.1.

\begin{defn}
Define the \textit{stabiliser} $\stab_G(x):=\{g\in G:g\ast x=x\}$. This is a subgroup of $G$, sometimes called \textit{symmetry group}.
\end{defn}

\begin{thm}[Orbit–Stabiliser]
For a finite $G$ acting on $X$ and $x\in X$,
\[
|G|=|\orb_G(x)|\cdot |\stab_G(x)|.
\]
\end{thm}

\begin{thm}
$G$ acts on itself by conjugation ($G\times G\rightarrow G:g\cdot h=ghg^{-1}$). In this case, orbit is \textit{conjugacy class} and stabiliser is \textit{centraliser}. An obvious corollary then follows from O–S.
\end{thm}

\begin{example}
\label{example:Snconjclas}
If $G=S_n$, then the conjugacy classes correspond to cycle types (ordered list of lengths of cycles), since
\[
\pi (a_1\ a_2\ \cdots \ a_k)\pi^{-1}=(\pi(a_1) \ \pi(a_2) \ \cdots \ \pi(a_k)).
\]
\end{example}

\subsection{Normal subgroup}

\begin{defn}
A subgroup is \textit{normal} if ...
\end{defn}
\begin{lemma}
Let $H$ be a subgroup of $G$. The following are equivalent.
\begin{enumerate}
\item $H$ is normal in $G$
\item $gHg^{-1}=H \ \forall g\in G$ \qquad (definition)
\item $gH=Hg \ \forall g\in G$
\end{enumerate}
\end{lemma}
\begin{example}
$SL_d(K)\unlhd GL_d(K)$ by determinant product.
\end{example}

\subsection{Homomorphism}

\begin{defn}
A \textit{group homomorphism} is ...

The \textit{kernel} and \textit{image} of a homomorphism are ...
\end{defn}

\begin{example}
\label{example:1stexofrep}
Consider $\phi:S_n\rightarrow GL_n(K)$ given by $\phi(e_i)=e_{\pi(i)}$, e.g.
\[
\pi=(1\ 2\ 3),\quad \phi(\pi)=\begin{pmatrix}
  0 & 0 & 1 \\ 1 & 0 & 0 \\ 0 & 1 & 0
\end{pmatrix}.
\]
Verify this is a group homomorphism and $\im(\phi)=\{1,-1\}$. Since $GL_n(K)\rightarrow K^\times$ by taking determinant is a also a homomorphism, one has
\[
\xymatrix{
    S_n\ar[r]^\phi \ar[dr]_{\sgn} & GL_n(K)\ar[d]^\det  \\ & K^\times
}
\]
where sign is a homomorphism and $\sgn(\pi)\in\{1,-1\}$. In fact, $\sgn(\pi)=1$ if $\pi$ is even and $-1$ if odd.
\end{example}

\begin{flushright}
\textit{Week 1, lecture 3 starts here}
\end{flushright}

\begin{thm}[1st isomorphism theorem]
If $\phi:G\rightarrow H$ is a homomorphism of groups, then
\begin{enumerate}
\item $\ker\phi\unlhd G$
\item $\im\phi\leq H$
\item $\hat\phi:G/\ker\phi\rightarrow\im\phi:g\ker\phi\mapsto\phi(g)$ is a well defined isomorphism.
\end{enumerate}
\end{thm}

\subsection{Dihedral group}
\begin{defn}
$D_{2n}:=\la r,s\mid r^n=1,s^2=1,srs^{-1}=r^{-1}\ra$ is called the \textit{dihedral group}.

It has two cyclic subgroups $\la r\ra\cong C_n,\la s\ra\cong C_2$.
\end{defn}

\subsection{Linear map}
\begin{defn}
Let $V,W$ be vector spaces over $K$. A map $T:V\rightarrow W$ is \textit{linear} if
\begin{enumerate}
\item $T(\alpha v)=\alpha T(v) \ \forall \alpha\in K,v\in V$
\item $T(v+w)=T(v)+T(w) \ \forall v,w\in V$
\end{enumerate}
\end{defn}

\begin{example}
$A\in M_{m\times n}(K)$ gives a linear map $T_A:K^n\rightarrow K^m,\ T_A(v)=Av$.
\end{example}

\begin{thm}[Rank–nullity]
\label{thm:rank-nullity}
If $V$ is finite dimensional and $T:V\rightarrow W$ a linear map, then
\[
\dim V=\dim\ker T+\dim\im T.
\]
\end{thm}

\begin{coro}
\label{coro:injequivsurjlinmapoverfindimV}
If $V$ is finite dimensional and $T:V\rightarrow V$ a linear map, then the following are equivalent.
\begin{enumerate}
\item $T$ is injective
\item $T$ is surjective
\item $T$ is an isomorphism
\end{enumerate}
\end{coro}

\begin{notation}
$GL(V):=\{T:V\rightarrow V\text{ isomorphism}\}$. This is a group.

If $V=K^n$ then $GL(V)\cong GL_n(K)$.
\end{notation}

\section{Group presentation}
In general, a group can be given uniquely (\textit{presented}) by $\la S\mid R\ra$ where $S$ is a set of symbols and $R$ relations. If $\exists S,R$ that are finite then $G$ is \textit{finitely presented}.

\begin{example}
$C_n=\la x\mid x^n=1\ra$.

$C_\infty=\la x \mid \ \ra=\{1,x,x^{-1},x^2,x^{-2},\ldots\}\cong (\Z,+)$.
\end{example}

\begin{thm}
\label{thm:homiffrelnholds}
Let $G=\la s_1,\ldots,s_n\mid R\ra$ and $H$ a group with $h_1,\ldots,h_n\in H$. Then $\exists$ a homomorphism $\phi:G\rightarrow H$ with $\phi(s_i)=h_i \ \forall i$ iff every relation $r\in R$ holds where all $s_i$ are replaced by $h_i$.
\end{thm}

\begin{example}
\label{example:Cnrep}
Consider $C_n$ and $\widehat{C_n}$, the set of group homomorphisms $C_n\rightarrow GL_1(\C)=\C^\times$, called the 1-dimensional complex representations of $C_n$. A candidate of $\phi(x)$ is a root of unity $\zeta=e^{\frac{2\pi i}{n}}$. If we write $\phi_j(x):=\zeta^j$ then
\[
\widehat{C_n}=\{\phi_0,\ldots,\phi_{n-1}\}.
\]
\end{example}

\begin{example}
Consider the 1-dimensional complex representations of $D_{2n}$. Note that $\phi(r)^n=1,\ \phi(s)^2=1$ and $\phi(s)\phi(r)\phi(s)^{-1}=\phi(r)^{-1}$, i.e. $\phi(r)^2=1$. If $n$ is even then we can have $\phi(r)=\pm 1,\ \phi(s)=\pm 1$, 4 representations. If $n$ is odd then we can only have $\phi(r)=1$ and $\phi(s)=\pm 1$, 2 representations.
\end{example}

\begin{flushright}
\textit{Week 2, lecture 1 starts here}
\end{flushright}

\section{Representation}
\subsection{Matrix representation}
\begin{defn}
Let $G$ be a group. A degree $d$ \textit{matrix representation} of $G$ over a field $K$ is a group homomorphism $\rho:G\rightarrow GL_d(K)$.
\end{defn}
\begin{example}
\label{example:D2n->GL2R}
Last time, we classified the degree 1 representations of $C_n$ and $D_{2n}$ over $\C$.

Consider a degree 2 representation of $D_{2n}$ over $\R$, i.e. a group homomorphism $D_{2n}\rightarrow GL_2(\R)$. Intuitively, we want to map to the corresponding rotation/reflection matrix, i.e.
\[
\phi(r) =R_{2\pi/n}=\begin{pmatrix}
\cos \frac{2\pi}{n} & -\sin \frac{2\pi}{n}\\
\sin \frac{2\pi}{n} & \cos \frac{2\pi}{n}
\end{pmatrix} \qquad \phi(s) =S=\begin{pmatrix}
1 & 0 \\ 0 & -1
\end{pmatrix}
\]
\end{example}

\begin{example}[Trivial degree $d$ matrix representation of $G$ over $K$] For all $g\in G$, define $\rho(g):=I_d\in GL_d(K)$, the identity matrix.
\end{example}

\begin{example}
Fix $A\in GL_d(K)$ and define $\rho:C_\infty\rightarrow GL_d(K)$ to be $\rho(x)=A$ (so that $\rho(x^i)=A^i$).
\end{example}

\begin{example}
Let $\theta\in\R$ and $R_\theta:=\begin{pmatrix}
\cos \theta & -\sin \theta\\
\sin \theta & \cos \theta
\end{pmatrix}$. Is there a degree 2 real representation of $C_n$ with $\rho(x)=R_\theta$? By \ref{thm:homiffrelnholds}, it's sufficient and necessary that $R_\theta^n=R_{n\theta}=I_2$, i.e. $n\theta\in 2\pi \Z$, i.e.
\[
\theta\in\{2\pi k/n : k\in\{0,\ldots,n-1\}\}.
\]
\end{example}

\begin{example}
$\sgn:S_n\rightarrow \C^\times$ is a degree 1 complex representation of $S_n$.
\end{example}

\begin{lemma}
Let $\rho:G\rightarrow GL_d(K)$ be a matrix representation and $P\in GL_d(K)$. Then $\rho':G\rightarrow GL_d(K):g\mapsto P\rho(g)P^{-1}$ is also a matrix representation.
\end{lemma}
\begin{proof}
One has $\rho'(gh)=P\rho(gh)P^{-1}=P\rho(g)\rho(h)P^{-1}=P\rho(g)P^{-1}P\rho(h)P^{-1}=\rho'(g)\rho'(h)$.
\end{proof}

\begin{defn}
Two degree $d$ matrix representations $\rho_1,\rho_2:G\rightarrow GL_d(K)$ are \textit{isomorphic} or \textit{equivalent} if $\exists P\in GL_d(K):\rho_2(g)=P\rho_1(g)P^{-1} \ \forall g\in G$, denoted $\rho_1\sim\rho_2$.
\end{defn}

\begin{lemma}
Two degree 1 representations $\theta_1,\theta_2:G\rightarrow GL_1(K)=K^\times$ are isomorphic iff they are equal.
\end{lemma}
\begin{proof}
If $\theta_1,\theta_2$ are isomorphic then $\exists:P\in K^\times:\theta_2(g)=P\theta_1(g)P^{-1}=\theta_1(g)$ since $P,\theta_1(g),P^{-1}\in K^\times$, a subset of a field.

If they are equal then they are isomorphic by definition.
\end{proof}

\begin{example}
By lemma above, none of the two representations of Example \ref{example:Cnrep} are isomorphic.
\end{example}

\begin{defn}
A representation $\rho:G\rightarrow GL_d(K)$ is \textit{faithful} if $\rho$ is injective.
\end{defn}

\subsection{Complex representations of $C_n$}
\begin{lemma}
\label{lemma:finordmatdiagevrou}
Let $A\in GL_d(\C)$ and suppose $A^n=I_d$ for some $n$. Then $\exists Q\in GL_d(\C):Q^{-1}AQ$ is diagonal with roots of unity $\theta_1,\ldots,\theta_d$ on the diagonal.
\end{lemma}
\begin{proof}
It suffices to prove $A$ is diagonalisable and all eigenvalues are roots of unity. Let $f(x)=x^n-1$, so that $f(A)=0$. Then $\mu_A(x)$ divides $f(x)$, so all its roots are distinct and are roots of unity.
\end{proof}

\begin{flushright}
\textit{Week 2, lecture 2 starts here}
\end{flushright}

\begin{thm}
Let $C_n=\la x\mid x^n=1\ra$ and $\rho:C_n\rightarrow GL_d(\C)$ a matrix representation. Then $\exists$ $n$th roots of unity $\theta_1,\ldots,\theta_d$ and a representation $\rho':C_n\rightarrow GL_d(\C)$ with $\rho\sim\rho'$ and
\[
\rho'(x^k)=\begin{pmatrix}
\theta_1^k & & 0 \\ & \ddots \\ 0&&\theta_d^k.
\end{pmatrix}
\]
\end{thm}
\begin{proof}
Let $A=\rho(x)$. Since $x^n=1,\ A^n=\rho(x^n)=I_d$. By lemma above, we can define $\rho'(x^k)=Q^{-1}\rho(x^k)Q$. By definition, $\rho'\sim\rho$. Now
\[
\rho'(x^k)=Q^{-1}\rho(x^k)Q=Q^{-1}A^kQ=(Q^{-1}AQ)^k,
\]
a power of a diagonal matrix, so it indeed has its desired form.
\end{proof}

\begin{example}
Suppose $n\geq 3$ and $\rho:C_n\rightarrow GL_2(\R)\subseteq GL_2(\C):x\mapsto R_{2\pi/n}$. Then $R_{2\pi/n}$ has complex eigenvalues $\zeta$ and $\zeta^{n-1}$ where $\zeta$ is the $n$th root of unity. So $\exists Q\in GL_2(\C):Q^{-1}R_{2\pi/n}Q=\begin{pmatrix}
\zeta & 0 \\ 0 & \zeta^{n-1}
\end{pmatrix}$, and we can define $\rho':C_n\rightarrow GL_2(\C)$ to be
\[
x^k\mapsto Q^{-1}\rho(x^k) Q=(Q^{-1}R_{2\pi/n}Q)^k=\begin{pmatrix}
\zeta^k & 0 \\ 0 & \zeta^{(n-1)k}
\end{pmatrix}.
\]
Note that by notation used in Example \ref{example:Cnrep}, we can write $\rho'(g)$ as $\begin{pmatrix}
\phi_1(g) & 0 \\ 0 & \phi_{n-1}(g).
\end{pmatrix}$ More generally, this is called \textit{decomposing} the representation and denoted $\rho'=\phi_1\oplus\phi_{n-1}$.
\end{example}

\begin{thm}
Every element of $Q_8=\la a,b \mid a^4=1,a^2=b^2,bab^{-1}=a^{-1}\ra$ can be written as $a^ib^j$ where $0\leq i\leq 3,\ 0\leq j\leq 1$. Moreover, $|Q_8|=8$.
\end{thm}
\begin{proof}
One has $a^{-1}=a^3$ and $b^{-1}=b^3$ since $b^4=(b^2)^2=(a^2)^2=a^4=1$, so we get rid of the inverses. Then we use $ba=a^7b$ to move all $b$ to the right, and use $a^4=1$ to reduce power of $a$ to under 3.

To prove the $4\times 2=8$ elements are distinct, define the group homomorphism $\phi:Q_8\rightarrow GL_2(\C):\phi(a)=\begin{pmatrix}i&0\\0&-i\end{pmatrix},\phi(b)=\begin{pmatrix}0&1\\-1&0\end{pmatrix}$. Then $|\la\phi(a)\ra|=4\mid |\im\phi|$, and since $\phi(b)\notin\la\phi(a)\ra,\ |\im\phi|>4$, and since $|\im\phi|\leq 8$, one concludes $|\im\phi|=8$. None of these matrices are similar, so $|Q_8|=8$.
\end{proof}

\section{Character: first encounter}
\begin{defn}
Let $\rho:G\rightarrow GL_d(K)$ be a representation. The \textit{character} of $\rho$ is $\chi_\rho:G\rightarrow\C:g\mapsto\tr(\rho(g))$. Note that this is not a homomorphism.
\end{defn}

\begin{flushright}
\textit{Week 2, lecture 3 starts here}
\end{flushright}

\begin{example}
$\rho:G\rightarrow \C^\times$ is a 1-dim representation. Then $\chi_\rho(g)=\rho(g)$. In this case, character is a group homomorphism since it's the same as the representation itself.
\end{example}

\begin{example}
$\rho:D_{2n}\rightarrow GL_2(\C):r\mapsto R_{2\pi/n}, s\mapsto \begin{pmatrix}1&0\\0&-1\end{pmatrix}$ (as in Example \ref{example:D2n->GL2R}).

Compute the values of the character:
\[
\chi_\rho(r^k)=\tr R_{2\pi k/n}=\tr \begin{pmatrix}
\cos \frac{2\pi k}{n} & -\sin \frac{2\pi k}{n} \\ \sin \frac{2\pi k}{n} & \cos \frac{2\pi k}{n}
\end{pmatrix}=2 \cos \frac{2\pi k}{n},
\]
and
\[
\chi_\rho(sr^k)=\tr\left( \begin{pmatrix}1&0\\0&-1\end{pmatrix}\begin{pmatrix}
\cos \frac{2\pi k}{n} & -\sin \frac{2\pi k}{n} \\ \sin \frac{2\pi k}{n} & \cos \frac{2\pi k}{n}
\end{pmatrix} \right)=\tr\begin{pmatrix}
\cos \frac{2\pi k}{n} & -\sin \frac{2\pi k}{n} \\ -\sin \frac{2\pi k}{n} & -\cos \frac{2\pi k}{n}
\end{pmatrix}=0.
\]
\end{example}

\subsection{Isomorphic representations have same character}
Recall that the character polynomial expands
\[
c_A(x)=\det (xI_d-A)=x^d-\tr(A)x^{d-1}+\cdots+(-1)^d \det(A).
\]

\begin{lemma}
\label{lemma:simmatsharecharpol}
Similar matrices have same character polynomial. In particular, they have same trace.
\end{lemma}
\begin{proof}
Let $B=Q^{-1}AQ$. Then
\[
\begin{aligned}
c_B(x)&=\det(xI_d-B)=\det\left(Q^{-1}xI_dQ-Q^{-1}AQ\right)=\det\left(Q^{-1}(xI_d-A)Q\right)\\
&=\det\left(Q^{-1}\right)\det(xI_d-A)\det(Q)=\det(xI_d-A)\\
&=c_A(x).
\end{aligned}
\]
\end{proof}

\begin{lemma}
\label{lemma:isorepcharsame}
Isomorphic representations have same character.
\end{lemma}
\begin{proof}
Let $\rho_1\sim\rho_2$, i.e. $\forall g,\ \rho_1(g)\sim\rho_2(g)$. By previous lemma, $\chi_{\rho_1}(g)=\tr(\rho_1(g))=\tr(\rho_2(g))=\chi_{\rho_2}(g)$.
\end{proof}
We will see later the converse also holds.

\subsection{Matrix of finite order}
\begin{lemma}
\label{lemma:traceoffinordmat}
Let $A\in GL_d(\C)$ with $A^n=I_d$ for some $n\in\N$. Then
\begin{enumerate}
\item $|\tr(A)|\leq d$
\item $|\tr(A)|=d$ iff $A=\theta I_d$ for an $n$th root of unity $\theta$
\item $\tr(A)=d$ iff $A=I_d$
\item $\tr\left(A^{-1}\right)=\overline{\tr(A)}$
\end{enumerate}
\end{lemma}
\begin{proof}
\begin{enumerate}
\item Recall Lemma \ref{lemma:finordmatdiagevrou} which says $A\sim \begin{pmatrix}\theta_1 & & \\& \ddots \\& & \theta_d\end{pmatrix}$, so by Lemma \ref{lemma:simmatsharecharpol} one has $\tr(A)=\theta_1+\cdots+\theta_d\leq d$. Triangle inequality gives
\[
|\tr(A)|\leq |\theta_1|+\cdots+|\theta_d|=d.
\]
\item The triangle inequality has equality iff $\theta_1=\cdots=\theta_d=\theta$, so $A=Q^{-1}\begin{pmatrix}
\theta & & \\
& \ddots \\
 & & \theta
\end{pmatrix}Q=Q^{-1}\theta Q=\theta I_d$.
\item The `if' is clear. If $\tr(A)=d$ then 2 tells us $\theta d=d$ so $\theta=1$ and $A=1I_d=I_d$.
\item Note that if $A$ has finite order then so does $A^{-1}$, so
\[
A^{-1}\sim Q^{-1}A^{-1}Q=\left(QAQ^{-1}\right)^{-1}=\begin{pmatrix}\theta_1 & & \\& \ddots \\& & \theta_d\end{pmatrix}^{-1}=\begin{pmatrix}\theta_1^{-1} & & \\& \ddots \\& & \theta_d^{-1}\end{pmatrix},
\]
hence $\tr\left(A^{-1}\right)=\theta_1^{-1}+\cdots+\theta_d^{-1}=\overline{\theta_1}+\cdots+\overline{\theta_d}=\overline{\theta_1+\cdots+\theta_d}=\tr(A)$.
\end{enumerate}
\end{proof}

\begin{flushright}
\textit{Week 3, lecture 1 starts here}
\end{flushright}

\subsection{First properties of character}
\begin{prop}
\label{prop:1stpropofchar}
Let $G$ be a finite group and $\rho:G\rightarrow GL_d(\C)$ a representation with character $\chi=\chi_\rho$. Then
\begin{enumerate}
\item $|\chi(g)|\leq d \ \forall g\in G$
\item $\chi(g)=d$ iff $\rho(g)=I_d$. In particular, $\chi(e)=d$.
\item $\chi\left(g^{-1}\right)=\overline{\chi(g)} \ \forall g\in G$
\item $\chi\left(h^{-1}gh\right)=\chi(g) \ \forall g,h\in G$, i.e. $\chi$ is constant on a conjugacy class (hence called \textit{class function})
\end{enumerate}
\end{prop}
\begin{proof}
Since $G$ is finite, every $g\in G$ has finite order, so its representation matrix also has finite order, hence 1–3 follow from \ref{lemma:traceoffinordmat}. For part 4, note that since $\rho$ is a homomorphism,
\[
\chi\left(h^{-1}gh\right)=\tr\left(\rho\left(h^{-1}gh\right)\right)=\tr\left(\rho(h)^{-1}\rho(g)\rho(h)\right)=\tr(\rho(g))=\chi(g).
\]
by \ref{lemma:simmatsharecharpol}.
\end{proof}

\section{Linear representation and $KG$-module}
\begin{defn}
Let $G$ be a group. A \textit{linear representation} of $G$ is a pair $(V,\rho)$ where $V$ is a vector space and $\rho:G\rightarrow GL(V)$ is a group homomorphism. $\dim V$ is the \textit{degree} or \textit{dimension} of $(V,\rho)$. We also say `$\rho:G\rightarrow GL(V)$ is a linear representation.'
\end{defn}

\begin{example}
Trivial representation $\rho:G\rightarrow GL(V):g\mapsto I_V$.
\end{example}

\begin{example}
$C_2=\la x \mid x^2=1\ra,\ \rho:C_2\rightarrow GL(V):1\mapsto I_V, x\mapsto -I_V$.
\end{example}

\begin{example}
$C_n=\la x \mid x^n=1\ra,\ \rho:C_n\rightarrow GL(V):x^i\mapsto\zeta_n^i I_V$ where $V$ is over $\C$.
\end{example}

\subsection{Correspondence between matrix representations and linear representations}
Let $\rho:G\rightarrow GL_d(K)$ be a matrix representation. For all $g\in G$, define $\theta_g:K^d\rightarrow K^d:v\mapsto \rho(g)v$. Clearly $\theta_g\in GL(K^d) \ \forall g\in G$. Now consider the map $\theta:G\rightarrow GL(K^d):g\mapsto\theta_g$. We claim this is a group homomorphism, and therefore is a linear representation. Indeed, $\theta(gh)(v)=\theta_{gh}(v)=\rho(gh)v=\rho(g)\rho(h)v=(\theta_g\theta_h)(v)$.

Now let $(V,\theta)$ be a linear representation with $\dim V=d<\infty$ and $(v_1,\ldots,v_d)$ a $K$-basis of $V$. For all $g\in G,\ \theta(g):V\rightarrow V$ has an associated matrix. Denote it $\rho(g)\in GL_d(K)$. (Verify that $\rho:G\rightarrow GL_d(K)$ is a group homomorphism.) If we take a different basis $w_1,\ldots,w_d$, we get $\rho'$ and there exists $P\in GL_d(K)$ (depending only on $v_1,\ldots,v_d,\ w_1,\ldots,w_d$) with $\rho'(g)=P\rho(g)P^{-1}\ \forall g\in G$, hence $\rho\sim\rho'$.

\subsection{The regular representation}
\label{subsection:regrep}
Let $|G|=n$ and $V$ the linear span of the $n$ many linearly independent vectors $v_g$, indexed by the group elements. Then $\dim V=n$. For $h\in G$, let $\reg_h\in\Hom(V,V)$ be defined via $\reg_h(v_g):=v_{hg}$. In particular, $\reg_h(\alpha_1v_{g_1}+\cdots+\alpha_nv_{g_n})=\alpha_1v_{hg_1}+\cdots+\alpha_nv_{hg_n}.$

\begin{flushright}
\textit{Week 3, lecture 2 starts here}
\end{flushright}

\begin{example}
$C_3=\la x\mid x^3=1\ra,\ V=\text{linspan}\{v_1,v_x,v_{x^2}\}$. Then $\reg_x(v_1)=v_x,\ \reg_x(v_x)=\reg_{x^2},\ \reg_x(v_{x^2})=v_1$, and the matrix of $\reg_x$ with respect to bases $(v_1,v_x,v_{x^2})$ is
\[
M=\begin{pmatrix}0&0&1\\1&0&0\\0&1&0\end{pmatrix}.
\]
Note that $\rho:C_3\rightarrow GL_3(\C):x\mapsto M$ is a group homomorphism.
\end{example}

\begin{lemma}
$\reg_h\in GL(V) \ \forall h\in G$.
\end{lemma}
\begin{proof}
One has to show bijectivity. Using Corollary \ref{coro:injequivsurjlinmapoverfindimV}, showing surjectivity suffices. Let $g\in G$. Then
\[
\reg_h(v_{h^{-1}g})=v_{hh^{-1}g}=v_g,
\]
hence $\im\reg_h$ contains every basis vector $v_g$.
\end{proof}
This gives a map $\reg:G\rightarrow GL(V)$.

\begin{lemma}
$\reg:G\rightarrow GL(V):h\mapsto \reg_h$ is a linear representation.
\end{lemma}
\begin{proof}
Let $h_1,h_2,g\in G$. Then
\[
\begin{aligned}
(\reg(h_1)\reg(h_2))(v_g)&=\reg(h_1)(\reg(h_2)(v_g))=\reg_{h_1}(\reg_{h_2}(v_g))\\
&=\reg_{h_1}(v_{h_2g})=v_{h_1h_2g}=\reg_{h_1h_2}(v_g)\\
&=\reg(h_1h_2)(v_g),
\end{aligned}
\]
so $\reg(h_1)\reg(h_2)=\reg(h_1h_2)$.
\end{proof}

\subsection{$KG$-module}
\begin{defn}
A \textit{linear action} of a group $G$ on a vector space $V$ over field $K$ is a map $\gamma:G\times V\rightarrow V:(g,v)\mapsto \gamma(g,v)$ such that $\forall u,v\in V,\ a\in K,\ g,h\in G$:
\begin{enumerate}
\item $\gamma(e,v)=v$
\item $\gamma(hg,v)=\gamma(h,\gamma(g,v))$ \makebox(0,0){\put(0,2.5\normalbaselineskip){%
               $\left.\rule{0pt}{1.5\normalbaselineskip}\right\}$ a group action of $G$ on $V$}}
\item $\gamma(g,u+v)=\gamma(g,u)+\gamma(g,v)$\makebox(0,-30){\put(0,2.5\normalbaselineskip){%
               $\left.\rule{0pt}{1.5\normalbaselineskip}\right\}$ $v\mapsto \gamma(g,v)$ is a linear map $\forall g\in G$}}
\item $\gamma(g,av)=a\gamma(g,v)$ 
\end{enumerate}
\end{defn}

\begin{defn}
A $KG$-\textit{module} is a vector space $V$ over $K$ equipped with a linear action $\gamma$ of $G$ on $V$.
\end{defn}

\begin{example}
$C_n=\la x\mid x^n=1\ra$ and $V$ is any $\C$-vector space. Let $x$ act by multiplication with $\zeta_n$, i.e. $\gamma(x,v)=\zeta_nv$. This is sufficient to define the action, since, for example, $\gamma(x^2,v)=\gamma(x,\gamma(x,v))=\gamma(x,\zeta_nv)=\zeta_n^2v$ by definition, and in general $\gamma(x^i,v)=\zeta_n^i v$.
\end{example}

\begin{notation}
$gv:=\gamma(g,v)=\rho(g)(v)$.
\end{notation}

\begin{prop}
Specifying a $KG$-module structure on a $K$-vector space $V$ is the same as specifying a linear representation $G\rightarrow GL(V)$.
\end{prop}
\begin{proof}
Let $\gamma:G\times V\rightarrow V$ be a $KG$-module. Define $\rho_g:V\rightarrow V:v\mapsto \gamma(g,v)$. By parts 3 and 4 of definition, $\rho_g$ is a linear map. By part 1, $\rho_e(v)=\gamma(e,v)=v$, so $\rho_e=I_V\in GL(V)$. Also, $(\rho_g \rho_h)(v)=\rho_g(\rho_h(v))=\gamma(g,\gamma(h,v))=\gamma(gh,v)=\rho_{gh}(v)$, so $\rho_{gh}=\rho_g\rho_h$. In particular, $\rho_g\rho_{g^{-1}}=\rho_e=I_V$, so $\rho_g\in GL(V)$. Therefore $\rho:G\rightarrow GL(V):g\mapsto \rho_g$ is a group homomorphism.

For the converse, we start with a linear representation $\rho:G\rightarrow GL(V)$ and define $\gamma:G\times V\rightarrow V:(g,v)\mapsto \rho(g)(v)$. Check this gives a linear action: 1 and 2 hold since $\rho$ is a group homomorphism, and 3 and 4 hold since each $\rho(g)$ is a linear map.
\end{proof}

\begin{flushright}
\textit{Week 3, lecture 3 starts here}
\end{flushright}

\begin{example}
$C_2=\la x\mid x^2=1\ra,\ V=\C^2$. Let $x$ act on $V$ via multiplication by $A:=\begin{pmatrix}0&1\\1&0\end{pmatrix}$. Then $\gamma$ is determined: $\gamma(x,v)=Av\ \forall v\in V$. Also, $\rho:C_2\rightarrow GL(V)$ is determined: $\rho(e)(v)=v \text{ (identity)},\ \rho(x)(v)=Av \ \forall v\in V$. Note that not every arbitrary $A$ works; verify the $\gamma$ and $\rho$ satisfy the definition axioms.
\end{example}

\begin{example}
$\rho:Q_8\rightarrow GL_2(\C),\ \rho(a)=\begin{pmatrix}i&0\\0&-i\end{pmatrix},\ \rho(b)=\begin{pmatrix}0&1\\-1&0\end{pmatrix}$. This makes $\C^2$ a $\C Q_8$-module via $\gamma(g,v)=\rho(g)(v)$. In other language, $a$ and $b$ act on $\C^2$ by multiplication with $A=\begin{pmatrix}i&0\\0&-i\end{pmatrix},\ B=\begin{pmatrix}0&1\\-1&0\end{pmatrix}$.
\end{example}

\section{Submodule and morphism}
\subsection{Submodule and reducibility}
\begin{defn}
Let $G$ be a group, $K$ a field and $V$ a $KG$-module. $W\subseteq V$ is a $KG$\textit{-submodule} of $V$ if
\begin{enumerate}
\item $W\subseteq V$ is a $K$-subspace
\item $gw\in W \ \forall w\in W, g\in G$
\end{enumerate}
\end{defn}

\begin{example}
$C_2=\la x\mid x^2=1\ra,\ V=\C^2$. Let $x$ act on $V$ via multiplication by $A:=\begin{pmatrix}1&0\\0&-1\end{pmatrix}$. The submodules are $\{0\},\ \C^2$ (the trivial ones), $\C\begin{pmatrix}1\\0\end{pmatrix}$ and  $\C\begin{pmatrix}0\\1\end{pmatrix}$.
\end{example}

\begin{lemma}
A $KG$-submodule is a $KG$-module. In the language of presentations, if $\rho:G\rightarrow GL(V)$ is a linear representation and $W\subseteq V$ is a $KG$-submodule, then $\rho':G\rightarrow GL(W)$ is also a linear representation, called a \textit{subrepresentation}.
\end{lemma}

\begin{defn}
A $KG$-submodule of $V$ is \textit{proper} if $W\neq V$, \textit{nontrivial} if $W\neq \{0\}$.

A nontrivial $KG$-module $V$ is \textit{reducible} if $V$ has a nontrivial proper submodule. Otherwise, it is \textit{irreducible} or \textit{simple}.
\end{defn}

\begin{example}
\label{example:realrepofCnirreducible}
$C_n=\la x\mid x^n=1\ra,\ \rho:C_n\rightarrow GL_2(\R),\ \rho(x)=R_{2\pi/n}$. We claim $\rho$ is irreducible if $n\geq 3$. It suffices to show any 1-d subspace $\R u$ where $u\neq 0$ of $\R^2$ are not $KG$-submodules. Indeed; let $\alpha u\in\R u$, then $x\alpha u=\alpha xu=\alpha R_{2\pi/n}u\notin\R u$.
\end{example}

\begin{example}
\label{example:Cinfxactsby1101}
$C_\infty=\la x\mid \ \ra,\ A=\begin{pmatrix}1&1\\0&1\end{pmatrix}$. Consider the $\C C_\infty$-module $V=\C^2$ with $x$ acting by multiplication with $A$. One can see $\C\begin{pmatrix}1\\0\end{pmatrix}$ is a 1-d subrepresentation, and we claim there are no other 1-d subrepresentations (i.e. no other nontrivial proper subrepresentations). Indeed, suppose $\C v$ where $v\neq 0$ is one, i.e. $Av=\lambda v$ for some $\lambda\in\C$, but $A$ only has one eigenvector $\begin{pmatrix}1\\0\end{pmatrix}$. If $A$ were $\begin{pmatrix}2&0\\0&3\end{pmatrix}$ then there would be two nontrivial proper subrepresentations, $\C\begin{pmatrix}1\\0\end{pmatrix}$ and $\C\begin{pmatrix}0\\1\end{pmatrix}$.
\end{example}

\begin{example}
If a group is generated by $g_1,\ldots,g_n$ and $V$ is a $KG$-module, then $V$ has a 1-dim $KG$-submodule iff $\rho(g_1),\ldots,\rho(g_n)$ have a common eigenvector. Indeed; the $\Leftarrow$ is trivial, and the $\Rightarrow$ follows from that if $Ku\subseteq V$ is a submodule, implying $g_i\alpha u\in Ku \ \forall i$, then $u$ is an eigenvector of $\rho(g_i)$ by definition.
\end{example}

\begin{flushright}
\textit{Week 4, lecture 1 starts here}
\end{flushright}

\begin{example}[\ref{example:realrepofCnirreducible} but over $\C$]
$C_n=\la x\mid x^n=1\ra,\ \rho:C_n\rightarrow GL_2(\C),\ \rho(x)=R_{2\pi/n}$ with $n\geq 3$. Now $R_{2\pi /n}$ has eigenvectors $\begin{pmatrix}1\\-i\end{pmatrix}$ and $\begin{pmatrix}1\\i\end{pmatrix}$ with eigenvalues $\zeta$ and $\zeta^{-1}$, so there are 4 submodules: $\{0\},\ \C\begin{pmatrix}1\\-i\end{pmatrix},\ \C\begin{pmatrix}1\\i\end{pmatrix}$ and $\C^2$.
\end{example}

\begin{example}[\ref{example:D2n->GL2R} but over $\C$]
$D_{2n}=\la r,s\mid r^n=s^2=1,\ srs^{-1}=r^{-1}\ra,\ V=\C^2$ with the same action and $n\geq 3$. There's no common eigenvectors of $R_{2\pi/n}$ and $S$, so $V$ has not proper nontrivial subrepresentations, hence irreducible.
\end{example}

\subsection{Reducible representation in terms of matrices}
\label{subsection:reducrepandblockdiagmat}
Let $V$ be a $d$-dimensional $KG$-module with submodule $U\subseteq V$. Choose a basis $v_1,\ldots,v_r$ of $U$ and extend it to a basis $v_1,\ldots,v_r,v_{r+1},\ldots,v_d$ of $V$. Let $\theta:G\rightarrow GL_d(K)$ be the matrix representation with respect to this basis. Write
\[
\theta(g)=(a_{ij}(g))_{1\leq i\leq d,\ 1\leq j\leq d} \qquad \text{with } \theta(g)(v_j)=a_{1j}(g)v_1+\cdots+a_{dj}(g)v_d, 
\]
but note that $\theta(g)(v_i)$ for $i=1,\ldots,r$ are expressed by solely $v_1,\ldots,v_r$, so the bottom left $d-r$ by $d-r$ is 0, i.e.
\[
\theta(g)=\begin{pmatrix}[cccc|ccc]
a_{11}(g) & a_{12}(g) & \cdots & a_{1r}(g) & a_{1r+1}(g) & \cdots & a_{1d}(g)\\
\vdots & \vdots & \ddots & \vdots & \vdots & \ddots & \vdots \\
a_{r1}(g) & a_{r2}(g) & \cdots & a_{rr}(g) & \vdots & & \vdots \\ \hline
0 & 0 & \cdots & 0 & a_{r+1r+1}(g) & \cdots & \vdots \\
\vdots & \vdots & \ddots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & 0 & a_{dr+1}(g) & \cdots & a_{dd}(g)
\end{pmatrix}=\begin{pmatrix}[c|c]
\phi(g)&\psi(g)\\ \hline
0 & \eta(g)
\end{pmatrix}.
\]
We also know $\theta$ is a homomorphism, hence
\[
\begin{aligned}
\theta(gh)=\begin{pmatrix}\phi(gh)&\psi(gh)\\0 & \eta(g)\end{pmatrix}&=\begin{pmatrix}\phi(g)&\psi(g)\\0 & \eta(g)\end{pmatrix}\begin{pmatrix}\phi(h)&\psi(h)\\0 & \eta(h)\end{pmatrix}=\theta(g)\theta(h)\\
\begin{pmatrix}\phi(g)\phi(h)&\psi(g)\psi(h)\\0&\eta(g)\eta(h)\end{pmatrix}&=\begin{pmatrix}\phi(g)\phi(h)&\phi(g)\psi(h)+\psi(g)\eta(h)\\0&\eta(g)\eta(h)\end{pmatrix},
\end{aligned}
\]
so $\underbrace{\phi:G\rightarrow GL_r(K)}_{U},\underbrace{\eta:G\rightarrow GL_{d-r}(K)}_{V/U}$ are homomorphisms, hence matrix representations.

\subsection{Permutation representation}
\begin{defn}
Given a group action $\gamma:G\times X\rightarrow X$ where $X=\{x_1,\ldots,x_d\}$, define $K$-vector space of formal linear combination of $v_{x_1},\ldots,v_{x_d}$, and linear action $g\cdot v_{x_i}:=v_{gx_i}$. This gives an element of $GL_d(K)$ determined by $g$, i.e. a representation $g(\alpha_1 v_{x_1}+\cdots+\alpha_d v_{x_d})=\alpha_1 v_{gx_1}+\cdots+\alpha_d v_{gx_d}$ called the \textit{permutation representation} or \textit{permutation module} to $\gamma$.
\end{defn}

\begin{example}
$G$ can act on itself by left multiplication $(g,h)\mapsto gh$ (which gives the regular representation; see \ref{subsection:regrep}), $(g,h)\mapsto hg^{-1}$ or $(g,h)\mapsto ghg^{-1}$.
\end{example}

\begin{example}
$S_n$ acts on $\{1,\ldots,n\}$ via $\pi i=\pi(i)$. Let $V=\text{linspan}\{v_1,\ldots,v_n\}$ with $\pi v_i=v_{\pi(i)}$. Then $v_1+\cdots+v_n$ is a 1-dimensional subrepresentation of $V$.
\end{example}

\begin{flushright}
\textit{Week 4, lecture 2 starts here}
\end{flushright}

\subsection{Morphism}

\begin{defn}
Let $V,W$ be $KG$-modules. A $K$-linear map $f:V\rightarrow W$ is a $G$-\textit{morphism} (or an \textit{equivariant map}, or simply \textit{morphism} of $KG$-modules) if $gf(v)=f(gv)\ \forall v\in V, g\in G$.
\end{defn}

\begin{notation}
$\Hom_G(V,W)=\{f:V\rightarrow W:f\text{ is a }G\text{-morphism}\}$. This is a vector space.
\end{notation}

\begin{defn}
A $G$-\textit{isomorphism} is a bijective $G$-morphism.
\end{defn}

\begin{lemma}
\label{lemma:kerimaresubrep}
If $f:V\rightarrow W$ is a $G$-morphism, then $\ker f$ and $\im f$ are subrepresentations of $V$ and $W$ respectively.
\end{lemma}
\begin{proof}
Since $f$ is linear, $\ker f$ and $\im f$ are linear subspaces of $V$ and $W$ respectively. It remains to show that
\begin{enumerate}
\item $gv\in\ker f \ \forall g\in G,v\in\ker f$. Indeed, $f(gv)=gf(v)=g0=0$ by definition, and
\item $gw\in\im f \ \forall g\in G,w\in\im f$. Indeed, let $v\in V:f(v)=w$, then $gw=gf(v)=f(gv)$.
\end{enumerate}
\end{proof}

\begin{example}
\label{example:S3perm}
Let $X=\{1,2,3\},\ G=S_3,\ V$ the permutation module $\{a_1e_1+a_2e_2+a_3e_3:a_1,a_2,a_3\in\C\}$ and $W=\C$ the trivial $\C S_3$-module, i.e. $gw=w \ \forall w\in W,g\in S_3$. Fix $0\neq w\in W$ and define $f:V\rightarrow W:a_1e_1+a_2e_2+a_3e_3\mapsto (a_1+a_2+a_3)w$. Verify $f$ is a $G$-morphism: $f$ is clearly a linear map, and one has
\[
\begin{aligned}
gf(a_1e_1+a_2e_2+a_3e_3)&=g(a_1+a_2+a_3)w=(a_1+a_2+a_3)w\\
&=\left(a_{g^{-1}(1)}+a_{g^{-1}(2)}+a_{g^{-1}(3)}\right)w=f(g(a_1e_1+a_2e_2+a_3e_3)).
\end{aligned}
\]
\end{example}

\subsection{Schur's lemma}
\begin{thm}[Schur's lemma I]
\label{thm:SchurslemmaI}
Let $G$ be a group, $K$ a field and $f:U\rightarrow V$ a $G$-morphism of irreducible $KG$-modules. Then either $f=0$ or $f$ is an isomorphism.
\end{thm}
\begin{proof}
One has $f=0$ iff $\ker f=U$ and $\im f=\{0\}$. Now suppose $f\neq 0$, then $\ker f\subsetneq U$ and $\{0\}\subsetneq \im f\subseteq V$, but by Lemma \ref{lemma:kerimaresubrep} and the assumption that $U,V$ are irreducible, $\ker f=\{0\}$ and $\im f=V$, i.e. $f$ is injective and surjective, i.e. $f$ is an isomorphism.
\end{proof}

\begin{thm}[Schur's lemma over $\C$]
\label{thm:SchurslemmaoverC}
Let $G$ be a group, $V$ a finite dimensional irreducible $\C G$-module and $f:V\rightarrow V$ a $G$-morphism. Then $f=\lambda I_V$ for some $\lambda\in\C$. In particular, $\dim\Hom_G(V,V)=1$.
\end{thm}
\begin{proof}
Let $\lambda$ be an eigenvalue of $f$ with eigenvector $u$. Let $f':V\rightarrow V:v\mapsto f(v)-\lambda v$. We claim $f'$ is a $G$-morphism. Indeed; it's clearly a linear map, and
\[
f'(gv)=f(gv)-\lambda gv=gf(v)-g\lambda v=g(f(v)-\lambda v)=gf'(v).
\]

\begin{flushright}
\textit{Week 4, lecture 3 starts here}
\end{flushright}

By Schur's lemma I, since $f'(u)=0$ and $u\neq 0$, one has $f'=0$, i.e. $f(v)=\lambda v \ \forall v\in V$, so equivalently $f'=\lambda I_V$ which is what's desired.
\end{proof}

\begin{example}[Schur's lemma over $\R$]
$C_3=\la x\mid x^3=1\ra,\ V$ the regular $C_3$-representation with basis $v_e,v_x,v_{x^2},\ W=\text{linspan}_\R\{v_e-v_x,v_x-v_{x^2}\}$ a subrepresentation. The matrix for this action of $x$ on $W$ is then $\rho(x)=\begin{pmatrix}0&-1\\1&-1\end{pmatrix}$, which has no real eigenvalues, hence no 1-dim subrepresentation, so irreducible.

To calculate the $\R$-vector space of $C_3$-morphisms $W\rightarrow W$, note that one needs by definition
\[
\begin{pmatrix}-c&-d\\a-c&b-d\end{pmatrix}=\begin{pmatrix}0&-1\\1&-1\end{pmatrix}\begin{pmatrix}a&b\\c&d\end{pmatrix}=\begin{pmatrix}a&b\\c&d\end{pmatrix}\begin{pmatrix}0&-1\\1&-1\end{pmatrix}=\begin{pmatrix}b&-a-b\\d&-c-d\end{pmatrix},
\]
i.e. $c=-b,d=a+b$ and the matrix is $\begin{pmatrix}a&b\\-b&a+b\end{pmatrix}$ which has two degrees of freedom $a$ and $b$, so $\dim_{C_3}(W,W)=2$.
\end{example}

\section{Maschke's theorem}
\subsection{Projection}
\begin{defn}
A map $f$ is called \textit{idempotent} if $f\circ f=f$. A such linear map $V\rightarrow U$ is a \textit{projection} if $f(u)=u \ \forall u\in U$.
\end{defn}
\begin{example}
$V=\R^2,\ U=\R\begin{pmatrix}1\\0\end{pmatrix}\subseteq V,\ f:V\rightarrow U:\begin{pmatrix}a\\b\end{pmatrix}\mapsto\begin{pmatrix}a\\0\end{pmatrix}$ is a projection. Note that $V=U\oplus\ker f$.
\end{example}

\begin{lemma}
Let $V$ be a finitely dimensional vector space and $U\subseteq V$ a linear subspace. Then $\exists $ a projection $f:V\rightarrow U$.
\end{lemma}
\begin{proof}
Let $v_1,\ldots,v_r$ be a basis for $U$ and $v_1,\ldots,v_r,v_{r+1},\ldots,v_d$ a basis for $V$. Define $f:V\rightarrow U$ by
\[
\alpha_1 v_1+\cdots+\alpha_d v_d \mapsto \alpha_1 v_1+\cdots+\alpha_r v_r,
\]
which is a projection.
\end{proof}

\begin{thm}
\label{thm:fprojimpVisUopkerf}
Let $f:V\rightarrow U$ be a projection. Then $V=U\oplus\ker f$.
\end{thm}
\begin{proof}
\begin{enumerate}
\item To show $V=U+\ker f$, let $v\in V$ and write $v=f(v)+v-f(v)$. Clearly $f(v)\in U$ and it remains to show $f(v-f(v))=0$, but $f(v-f(v))=f(v)-f(f(v))=f(v)-f(v)=0$ by idempotence.
\item To show $U\cap\ker f=\{0\}$, let $u\in U\cap\ker f$, then $f(u)=u$ and $f(u)=0$, so $u=0$.
\end{enumerate}
\end{proof}

\subsection{Semisimplicity and complementary modules}
\begin{defn}
A $KG$-module $V$ is \textit{semisimple} if $\forall KG$-submodules $U,\ \exists$ a $KG$-submodule $W\subseteq V$ such that $V=U\oplus W$, where $U$ and $W$ are \textit{complementary}. 
\end{defn}

\begin{example}
If $V$ is irreducible then the only submodules are $\{0\}$ and $V$, which are complementary, hence every irreducible representation is semisimple.
\end{example}

\begin{example}
Recall Example \ref{example:Cinfxactsby1101} where we have three submodules $\{0\},\C\begin{pmatrix}1\\0\end{pmatrix}$ and $\C^2$. Hence the representation is not semisimple since $\C\begin{pmatrix}1\\0\end{pmatrix}$ has no complementary submodule. If we again replace $A$ by a diagonal matrix then it would be semisimple ($\C\begin{pmatrix}1\\0\end{pmatrix}$ and $\C\begin{pmatrix}0\\1\end{pmatrix}$ are complementary).
\end{example}

\begin{flushright}
\textit{Week 5, lecture 1 starts here}
\end{flushright}

\subsection{Maschke's theorem}
\begin{lemma}[Averaging]
Let $G$ be a finite group, $K$ a field with $|G|\cdot 1_K\neq 0_K$ (i.e. $\Char K\nmid |G|$) and $U,V$ be $KG$-modules with $f:U\rightarrow V$ a linear map. Define
\[
f':V\rightarrow U:v\mapsto \frac{1}{|G|}\sum_{g\in G} g\left(f\left(g^{-1}v\right)\right),
\]
then $f'$ is a $G$-morphism.

(cf. HW5, Exe 3)
\end{lemma}
\begin{proof}
Let $h\in G$, then
\[
\begin{aligned}
f'(hv)&=\frac{1}{|G|}\sum_{g\in G} g\left(f\left(g^{-1}hv\right)\right)=h\frac{1}{|G|}\sum_{g\in G} h^{-1} gf\left(\left(h^{-1}g\right)^{-1}v\right)\\
&=h\frac{1}{|G|}\sum_{h^{-1}g\in G} h^{-1} gf\left(\left(h^{-1}g\right)^{-1}v\right)=h(f'(v)).
\end{aligned}
\]
\end{proof}

\begin{thm}[Maschke's]
\label{thm:Maschkes}
Let $G$ be a finite group and $K$ a field with $|G|\cdot 1_K\neq 0_K$. Then every finite dimensional $KG$-module is semisimple.
\end{thm}
\begin{proof}
Let $U\subseteq V$ be a $KG$-submodule. We want to show $\exists W\subseteq V$ a $KG$-submodule such that $V=U\oplus W$. Let $f:V\rightarrow U$ be a projection and $f'\in\Hom_G(V,U)$ as in lemma above. We claim $f'$ is idempotent and $\im f'=U$. Indeed; since $f'(v)\in U \ \forall v\in V$, it suffices to show $f'(u)=u \ \forall u\in U$:
\[
\begin{aligned}
f'(u)&=\frac{1}{|G|}\sum_{g\in G}g\left(f\left(g^{-1}u\right)\right) \\
&=\frac{1}{|G|}\sum_{g\in G}g\left(g^{-1}u\right) \qquad \text{since }g^{-1}u\in u\text{ and }f\text{ is a projection}\\
&=\frac{1}{|G|}\sum_{g\in G}u\\
&=\frac{1}{|G|}|G|u=u.
\end{aligned}
\]
Hence, by Theorem \ref{thm:fprojimpVisUopkerf}, $V=U\oplus\ker f'$ where $\ker f'$ is indeed a $KG$-submodule by \ref{lemma:kerimaresubrep}.
\end{proof}

\begin{coro}
Let $G$ be a group, $K$ a field with $|G|\cdot 1_K\neq 0_K$ and $V$ a finite dimensional $KG$-module. Then $\exists$ irreducible submodules $U_1,\ldots,U_j$ such that $V=U_1\oplus U_2\oplus\cdots\oplus U_j$.
\end{coro}
\begin{proof}
Induction on $\dim V$. If $\dim V=1$ then $V$ is irreducible hence we are done. Now let $\dim V>1$. If $V$ is irreducible then we are again done, so suppose $V$ is reducible and let $U\subseteq V$ be a nontrivial proper subrepresentation with complementary $W$, whose existence is guaranteed by Maschke's theorem. Note that $\dim U,\dim W<\dim V$, so by inductive hypothesis $U=U_1\oplus\cdots\oplus U_r,W=U_{r+1}\oplus\cdots\oplus U_k$ where $U_i$ irreducible, hence $V=U\oplus W=U_1\oplus\cdots\oplus U_k$.
\end{proof}

\begin{remark}[On cyclic groups]
We actually have seen Maschke's theorem and its corollary for specifically cyclic groups $C_n$ already, and as corollaries, all irreducible representations of $C_n$ are 1-dimensional, and there are exactly $n$ many non-isomorphic irreducible representations of $C_n$.
\end{remark}

\begin{flushright}
\textit{Week 5, lecture 2 starts here}
\end{flushright}

\subsection{Orthogonality relations of characters}
\begin{notation}
$\C^G:=\{f:G\rightarrow\C\}$. Note that $\C^G\cong \C G$ as a vector space and $\dim \C^G=|G|$.
\end{notation}

\begin{lemma}
\label{lemma:charofsumissumofchar}
Let $V=U_1\oplus\cdots\oplus U_k$ be a decomposition of a $KG$-module $V$, then $\chi_{V}=\chi_{U_1}+\cdots+\chi_{U_k}$.
\end{lemma}
\begin{remark}
Note that Maschke's theorem does not give us uniqueness of the decomposition, but the equation stated will independently hold.
\end{remark}
\begin{proof}
Choose a basis of $V$ by choosing a basis for each $U_i$, then matrices $\rho(g)$ are block diagonal with respect to this basis (cf. Section \ref{subsection:reducrepandblockdiagmat}):
\[
\rho_V(g)=\begin{pmatrix}[c|c|c]
\rho_{U_1}(g) & 0 & 0 \\ \hline
0 & \ddots & 0 \\ \hline
0 & 0 & \rho_{U_k}(g)
\end{pmatrix},
\]
and by definition of character (trace of the matrix) one has what's desired.
\end{proof}

From now on we fix the field $\C$ and group $G$ to be finite. Write $V\in\Mod G$ to say `$V$ is a finite dimensional $\C G$-module'.

\begin{lemma}
\label{lemma:ftildeistrfoverdimVIV}
Let $V\in\Mod G$ be irreducible and $f\in\Hom(V,V)$. Define
\[
\widetilde f\in\Hom_G(V,V)\quad\text{by}\quad v\mapsto \frac{1}{|G|}\sum_{g\in G}g\left(f\left(g^{-1}v\right)\right).
\]
Then
\[
\widetilde f=\frac{\tr(f)}{\dim V} I_V
\]
\end{lemma}
\begin{proof}
Schur's lemma over $\C$ (\ref{thm:SchurslemmaoverC}) tells us indeed $\widetilde f=\lambda I_V$ for some $\lambda\in\C$. Now one has
\[
\begin{aligned}
\lambda\dim V&=\tr(\lambda I_V)=\tr\left(\frac{1}{|G|}\sum_{g\in G}\rho(g)\circ f\circ \rho\left(g^{-1}\right)\right)\\
&=\frac{1}{|G|}\sum_{g\in G}\tr\left(\rho(g)\circ f\circ \rho(g)^{-1}\right)\\
&=\tr(f). \qquad \text{by \ref{lemma:simmatsharecharpol}}
\end{aligned}
\]
\end{proof}

\begin{defn}
For $\varphi,\psi\in\C^G$, define the \textit{inner product}
\[
\la \varphi,\psi\ra:=\frac{1}{|G|}\sum_{g\in G}\varphi(g)\overline{\psi(g)}.
\]
Note that this is a Hermitian inner product on $\C^G$, i.e. $\forall\varphi,\psi,\xi\in\C^G,\ \alpha\in\C$,
\begin{enumerate}
\item $\la\varphi,\psi\ra=\overline{\la\psi,\varphi\ra}$
\item $\la\alpha\varphi+\xi,\psi\ra=\alpha\la\varphi,\psi\ra+\la\xi,\psi\ra$
\item $\la\psi,\alpha\varphi+\xi\ra=\overline\alpha\la\varphi,\psi\ra+\la\xi,\psi\ra$
\item $\la\psi,\psi\ra\geq 0$
\end{enumerate}
\end{defn}

\begin{thm}[Orthogonality relations]
\label{thm:orthogonalityrelations}
Let $U,V\in\Mod G$ be irreducible. Then
\[
\la\chi_U,\chi_V\ra=\left\{ \begin{aligned}
  1 \qquad &\text{if }U\sim V\\
  0 \qquad &\text{otherwise}
\end{aligned} \right.
\]
\end{thm}
\begin{proof}
One has
\[
\begin{aligned}
\la\chi_U,\chi_V\ra&=\frac{1}{|G|}\sum_{g\in G}\chi_u(g)\chi_V(g^{-1}) \qquad \text{by \ref{prop:1stpropofchar}}\\
&=\frac{1}{|G|}\sum_{g\in G} \left(\sum_i\rho_U(g)_{i,i}\right)\left(\sum_j\rho_V\left(g^{-1}\right)_{j,j}\right)\qquad \text{by definition}\\
&=\sum_{i,j}\left(\frac{1}{|G|}\sum_{g\in G}\rho_U(g)_{i,i}\rho_V\left(g^{-1}\right)_{j,j}\right)\\
&=\sum_{i,j}\left(\frac{1}{|G|}e_i^T\rho_U(g)e_ie_j^T\rho_V\left(g^{-1}\right)e_j\right)\\
&=\sum_{i,j}\left(e_i^T\left(\frac{1}{|G|}\sum_{g\in G}\rho_U(g)E_{i,j}\rho_V\left(g^{-1}\right)\right)e_j\right)\\
&=\sum_{i,j}\left(e_i^T\underbrace{\widetilde{E_{i,j}}}_{\in\Hom_G(V,U)}e_j\right) \qquad \text{by definition in \ref{lemma:ftildeistrfoverdimVIV}}
\end{aligned}
\]
By Schur's lemma (\ref{thm:SchurslemmaI}), if $U\not\sim V$ then $\widetilde{E_{i,j}}=0$. If $U\sim V$ then $\chi_U=\chi_V$, so it suffices to treat the case $U=V.\ \widetilde{E_{i,i}}$ is then diagonal by \ref{thm:SchurslemmaoverC}, hence
\[
\sum_i e_i^T\widetilde{E_{i,i}}e_i=\tr\left(\widetilde{E_{i,i}}\right)=\dim V\frac{\tr(E_{i,i})}{\dim V}=1
\]
by Lemma \ref{lemma:ftildeistrfoverdimVIV}.
\end{proof}

\begin{flushright}
\textit{Week 5, lecture 3 starts here}
\end{flushright}

\begin{coro}
\label{coro:nofpwniirfdisatmostnofconjclas}
The number of pairwise nonisomorphic irreducible finite-dimensional $\C G$-modules is at most the number of conjugacy classes in $G$.
\end{coro}
\begin{proof}
By \ref{thm:orthogonalityrelations}, the characters of pairwise nonisomorphic irreducible finite-dimensional $\C G$-modules form an orthonormal system in the vector space $V=\{\chi\in\C^G:\chi\text{ class function}\}$, which implies the number of them cannot exceed $\dim V$ (you cannot have four vectors pairwise perpendicular in a 3-d space), which is the number of conjugacy class in $G$.
\end{proof}

\begin{coro}
\label{coro:convisorepcharsame}
For $U,V\in\Mod G$, one has $U\sim V$ iff $\chi_U=\chi_V$.
\end{coro}
\begin{proof}
It suffices to show the $\Leftarrow$ by Lemma \ref{lemma:isorepcharsame}. Let $W_1,\ldots,W_r\in\Mod G$ be a complete list of pairwise nonisomorphic irreducibles. Now, by Maschke's theorem (\ref{thm:Maschkes}) one can write $U\sim\bigoplus_{i=1}^r W_i^{\oplus n_i}$ and $V\sim\bigoplus_{i=1}^r W_i^{\oplus m_i}$ where $n_i,m_i\in\N$. By \ref{lemma:charofsumissumofchar} and assumption,
\[
\chi_U=\sum_{i=1}^r n_i \chi_{W_i}=\sum_{i=1}^r m_i \chi_{W_i}=\chi_V.
\]
Now by \ref{thm:orthogonalityrelations}, $\chi_{W_i}$ are linearly independent, so the coefficients are uniquely determined and $n_i=m_i \ \forall i$, and $U\sim V$ immediately follows.
\end{proof}

\begin{defn}
Let $U\in\Mod G$ be irreducible and $W\in\Mod G$. Define the \textit{multiplicity} of $U$ in $W$ as
\[
\mult_U(W):=\la \chi_U,\chi_W\ra.
\]
\end{defn}

\begin{prop}
Let $U\in\Mod G$ be irreducible and $W\in\Mod G$. For any decomposition $W=\bigoplus_{i=1}^k U_i$, one has
\[
\mult_U(W)=|\{i\in\{1,\ldots,k\}:U\sim U_i\}|.
\]
\end{prop}
\begin{proof}
Let $W_1,\ldots,W_r\in\Mod G$ be a complete list of pairwise nonisomorphic irreducibles. One then has
\[
\chi_W=\sum_{i=1}^k \chi_{U_i}=\sum_{j=1}^r n_j \chi_{W_j} \quad\text{where }n_j=|\{i\in\{1,\ldots,k\}:U_i\sim W_j\}|.
\]
By \ref{thm:orthogonalityrelations}, one sees
\[
\begin{aligned}
\mult_U(W)&=\la\chi_U,\sum_{j=1}^r n_j \chi_{W_j}\ra=\sum_{j=1}^r n_j\la\chi_U,\chi_{W_j}\ra\\
&=0+\cdots+n_{j_0}\la\chi_U,\chi_{j_0}\ra+\cdots+0=n_{j_0}
\end{aligned}
\]
where $j_0\in\N:U\sim W_{j_0}$.
\end{proof}

\begin{lemma}
\label{lemma:irrediffinnerprod1}
$U\in\Mod G$ is irreducible iff $\la\chi_U,\chi_U\ra=1$.
\end{lemma}
\begin{proof}
It suffices to show the $\Leftarrow$ by Theorem \ref{thm:orthogonalityrelations}. Let $W_1,\ldots,W_k\in\Mod G$ be a complete list of pairwise nonisomorphic irreducibles. Use Maschke's (\ref{thm:Maschkes}) to write
\[
U\sim\bigoplus_{j=1}^k W_j^{\oplus n_j}\text{ and hence }\chi_U=\sum_{j=1}^k n_j\chi_{W_j}.
\]
where $n_j\in\N$, then by \ref{thm:orthogonalityrelations} and assumption,
\[
\la\chi_U,\chi_U\ra=\sum_{i,j=1}^k n_in_j\la\chi_{W_i},\chi_{W_j}\ra=\sum_{i=1}^k (n_i)^2=1,
\] 
which means one $n_i=1$ and all other $n_i=0$, so $U\sim W_i$ for some $i$, i.e. $U$ is irreducible.
\end{proof}

\subsection{Decomposition of regular representation}
\begin{lemma}
\label{lemma:sumirreddimsqisordG}
Let $W_1,\ldots,W_k\in\Mod G$ be a complete list of pairwise nonisomorphic irreducibles. Then
\[
\sum_{i=1}^k(\dim W_i)^2=|G|.
\]
\end{lemma}
\begin{proof}
Let $\C G$ denote the regular representation. First note $\dim (\C G)=|G|$, and since $\reg_g$, a permutation of basis vectors, has no fixed points as long as $g\neq e$ and hence only zeros along the diagonal, one has
\[
\begin{aligned}
\mult_{W_i}(\C G)&=\la \chi_{\C G},\chi_{W_i}\ra=\frac{1}{|G|}\sum_{g\in G}\underbrace{\overline{\chi_{\C G}(g)}}_{=0\text{ if }g\neq e}\chi_{W_i}(g)\\
&=\frac{1}{|G|}\overline{\chi_{\C G}(e)}\chi_{W_i}(e)=\frac{1}{|G|}\dim W_i=\dim W_i.
\end{aligned}
\]
Now since
\[
\C G\sim\bigoplus_{i=1}^k W_i^{\oplus \mult_{W_i}(\C G)}=\bigoplus_{i=1}^k W_i^{\dim W_i},
\]
one has $|G|=\dim\C G=\sum_{i=1}^k(\dim W_i)^2$.
\end{proof}

\begin{flushright}
\textit{Week 6, lecture 1 starts here}
\end{flushright}

\begin{defn}
A character $\chi$ is \textit{irreducible} if $\chi$ is the character of an irreducible representation $V\in\Mod G$.
\end{defn}

\begin{example}
$G=C_3=\la x\mid x^3=1\ra$. Recall the 3 irreducible characters: let $\zeta\in\C$ a primitive 3rd root of unity. Note since $G$ is abelian it has $|G|=3$ conjugacy classes. Consider the character table

\begin{table}[H]
\centering
\begin{tabular}{c|ccc}
         & $\{1\}$ & $\{x\}$   & $\{x^2\}$       \\ \hline
$\chi_0$ & 1       & 1         & 1               \\
$\chi_1$ & 1       & $\zeta$   & $\zeta^2$       \\
$\chi_2$ & 1       & $\zeta^2$ & $\zeta^4=\zeta$
\end{tabular}
\end{table}
One verifies that
\[
\begin{aligned}
\la\chi_0,\chi_1\ra&=\frac13\left(1\cdot 1+1\cdot\overline\zeta+1\cdot \overline{\zeta^2}\right)=\frac13\left(1+\zeta^2+\zeta\right)=0,\\
\la\chi_1,\chi_1\ra&=\frac13\left(1\cdot 1+\zeta\cdot\overline\zeta+\zeta^2\cdot\overline{\zeta^2}\right)=\frac13\left(1+\zeta^3+\zeta^3\right)=1,\\
\la\chi_2,\chi_1\ra&=\frac13\left(1\cdot 1+\zeta^2\cdot\overline\zeta+\zeta\cdot \overline{\zeta^2}\right)=\frac13\left(1+\zeta^4+\zeta^2\right)=0.
\end{aligned}
\]
\end{example}

\begin{example}
$G=C_n$ and $\zeta$ is a primitive $n$th root of unity. Generalising from example above, one sees the character table is now an $n\times n$ matrix whose $(i,j)$th entry (counting from zero) is $\zeta^{ij},\ 0\leq i,j<n$. (Known as the Vandermonde matrix.)
\end{example}

\begin{example}
$G=S_3,\ S=\{1,2,3\}$ and $V$ is the corresponding permutation representation (note $\dim V=3$). We've seen in Example \ref{example:1stexofrep} the 1-d representation sign with character
\[
\chi_{\text{sign}}(e)=1,\qquad \chi_{\text{sign}}((12))=-1,\qquad \chi_{\text{sign}}((123))=1.
\]

Now let $U:=\C(e_1+e_2+e_3)$ and consider $V/U$ with basis $(e_1+U,e_2+U)$ (and $e_3=-e_1-e_2$), then
\begin{alignat*}{3}
&\rho_{V/U}(e)=\begin{pmatrix}1&0\\0&1\end{pmatrix}\qquad &&\rho_{V/U}((12))=\begin{pmatrix}0&1\\1&0\end{pmatrix}\qquad&&\rho_{V/U}((123))=\begin{pmatrix}0&-1\\1&-1\end{pmatrix}\\
&\tr=2 &&\tr=0 &&\tr=-1
\end{alignat*}
We can use \ref{lemma:irrediffinnerprod1} to check that $V/U$ is irreducible:
\[
\la\chi_{V/U},\chi_{V/U}\ra=\frac16\left(2^2+3\times 0^2+2\times(-1)^2\right)=\frac16\times 6=1.
\]

Verify \ref{lemma:sumirreddimsqisordG}: $2^2+1^2+1^2=6.$
\end{example}

\subsubsection{The Wedderburn isomorphism}
\begin{defn}
A $\C$-algebra $A$ is a $\C$-vector space and a ring such that the scalar multiplication and ring multiplication are compatible, i.e. $\exists$ an injective ring homomorphism $\iota:\C\rightarrow A$ with
\[
\alpha\cdot_\C a=\iota(\alpha)\cdot_A a \qquad \forall \alpha\in\C,a\in A.
\]
\end{defn}

\begin{example}
Let $\End(V):=\Hom(V,V)$, which is a $\C$-algebra via $\iota(\alpha)=\alpha I_V$. Note $GL(V)\subsetneq \End(V)$. Also $\C G$ is a $\C$-algebra via the product
\[
\left(\sum_{g\in G}\alpha_g g\right)\left(\sum_{h\in G}\beta_h h\right)=\sum_{g'\in G,gh=g'}(\alpha_g\beta_h)g',
\]
the `linear continuation' of action of $G$ on regular representation $\C G$.
\end{example}

\begin{thm}[Wedderburn's]
\label{thm:Wedderburns}
Let $W_1,\ldots,W_k\in\Mod G$ be a complete list of pairwise nonisomorphic irreducibles and
\[
\begin{aligned}
f:\C G&\rightarrow\End(W_1)\times\cdots\times\End(W_k)\\
g&\mapsto \left(\rho_{W_1}(g),\ldots,\rho_{W_k}(g)\right).
\end{aligned}
\]
Then $f$ is an isomorphism of $\C$-algebras.
\end{thm}

\begin{flushright}
\textit{Week 6, lecture 2 starts here}
\end{flushright}

\begin{remark}
Let $V$ be a $\C$-algebra and a $G$-representation whose group action is compatible with the ring multiplication $\cdot_V$ as follows:
\[
(gh)1_V=(g1_V)\cdot_V(h1_V).
\]
A $G$-homomorphism from $\C G$ with $f(1_{\C G})=1_V$ is always a ring homomorphism, hence a $\C$-algebra homomorphism, since
\[
\begin{aligned}
f\left(\left(\sum_{g\in G}\alpha_g g\right)\left(\sum_{h\in H}\beta_h h\right)\right)&=f\left(\sum_{g,h\in G}(\alpha_g\beta_h)gh\right)=\sum_{g,h\in G}\alpha_g\beta_h f(gh)\\
&=\sum_{g,h\in G}\alpha_g\beta_h f(g)f(h)=\left(\sum_{g\in G}\alpha_g f(g)\right)\left(\sum_{h\in G}\beta_h f(h)\right)\\
&=f\left(\sum_{g\in G}\alpha_g g\right)f\left(\sum_{h\in G}\beta_h h\right).
\end{aligned}
\]
\end{remark}

\begin{proof}[Proof of \ref{thm:Wedderburns}]
$f$ is a linear map and a $G$-morphism, hence a $\C$-algebra morphism. By \ref{lemma:sumirreddimsqisordG}, the dimensions are equal so by \ref{thm:rank-nullity} it suffices to show either injectivity or surjectivity. Consider $\displaystyle a=\sum_{g\in G}\alpha_g g\in\ker f$. Then
\[
\forall i\in\{1,\ldots,k\},\ \sum_{g\in G}\alpha_g\rho_{W_i}(g)=:\rho_{W_i}(a)=0,
\]
i.e. $\forall w\in W_i,\ \rho_{W_i}(a)(w)=0$. By construction of $W_i$'s and Maschke's theorem (\ref{thm:Maschkes}), one has $\forall V\in\Mod G,\ \rho_V(a)=0$. In particular for $V=\C G,\ \forall b\in\C G,\ a\cdot_{\C G}b=0$, hence $a=a\cdot_{\C G}1_G=0$.
\end{proof}

\begin{defn}
The \textit{centre} of a $\C$-algebra $A$ is the linear subspace $Z(A)\subseteq A$ defined as
\[
Z(A)=\{a\in A:ab=ba\ \forall b\in A\}.
\]
\end{defn}
\begin{notation}
$\Cl_G:=\{\text{conjugacy classes in }G\}$.
\end{notation}
\begin{prop}
$\dim Z(\C G)=|\Cl_G|$.
\end{prop}
\begin{proof}
First note that $\forall b\in \C G,\ ab=ba\iff \forall h\in G,\ ah=ha\iff \forall h\in G,\ hah^{-1}=a$. Write $a=\sum_{g\in G}\alpha_g g$. One has $hah^{-1}=a$ iff
\[
\sum_{g\in G}\alpha_g g=\sum_{g\in G}\alpha_g hgh^{-1}=\sum_{g'\in G}\alpha_{h^{-1}g'h}g' \iff \forall g\in G,\ \alpha_g=\alpha_{h^{-1}gh},
\]
so $a\in Z(G)\iff\alpha:G\rightarrow\C$ is constant on conjugacy classes. The vector space of such $\alpha$ hence has dimension $|\Cl_G|$.
\end{proof}

\begin{coro}
\label{coro:nofpairwisenonisoirredrepofGisnofclG}
The number of pairwise nonisomorphic irreducible representations of $G$ equals $|\Cl_G|$.
\end{coro}
\begin{proof}
By \ref{thm:Wedderburns} one has
\[
\dim Z(\C G)=|\Cl_G|=\dim Z(\End(W_1)\times\cdots\times\End(W_1)).
\]

Note that $Z(\End(W))=\C I_w$ (the only matrices that commute with any other matrix are the ones that are diagonal with same entries on the diagonal), which is 1-dimensional. More generally,
\[
Z(\End(W_1)\times\cdots\times\End(W_1))=Z(\End(W_1))\times\cdots\times Z(\End(W_k))
\]
which is $k$-dimensional.
\end{proof}

\begin{notation}
$\C^{\Cl_G}=\{f:\Cl_G\rightarrow \C\}$, which we identify with the set of class functions $\C^G$.
\end{notation}

\begin{coro}
The characters of irreducible representations of $G$ form a basis of vector space $\C^{\Cl_G}$.
\end{coro}
\begin{proof}
By \ref{thm:orthogonalityrelations}, the irreducibles characters are linearly independent, and by \ref{coro:nofpairwisenonisoirredrepofGisnofclG} the number of such characters equals $\dim \C^{\Cl_G}=|\Cl_G|$.
\end{proof}

\begin{flushright}
\textit{Week 6, lecture 3 starts here}
\end{flushright}

\subsubsection{Character tables}
\begin{defn}
The \textit{character table} of $G$ is the square matrix whose columns are indexed by conjugacy classes $\Cl_G(g_i)$ and rows are index by $W_j$ with entries $\chi_{W_j}(g_i)$.
\end{defn}
\begin{example}
The character table of $S_3$ (the subscripts indicate sizes of conjugacy classes):
\begin{table}[H]
\centering
\begin{tabular}{c|ccc}
$S_3$                              & $\id_1$ & $(12)_3$  & $(123)_2$ \\ \hline
triv                                 & 1 & 1    & 1     \\
sign                                 & 1 & $-1$ & 1     \\
$\la e_1,e_2,e_3\ra/\C(e_1+e_2+e_3)$ & 2 & 0    & $-1$ 
\end{tabular}
\end{table}

Theorem \ref{thm:orthogonalityrelations} tells us if one multiplies each column $g$ in the table by $\sqrt{\frac{|\Cl_G(g)|}{|G|}}$ one obtains a matrix $A$ with orthogonal rows of norm 1 (in the sense of standard Hermitian inner product $\la v,w\ra:=\sum_{i=1}^n v_i\overline{w_i}$ for $v,w\in\C^n$), i.e. orthonormal rows:

\begin{table}[H]
\centering
\begin{tabular}{c|ccc}
$G=S_3$                              & 1                   & $x$                  & $x^2$                \\ \hline
triv                                 & $\frac{1}{\sqrt 6}$ & $\frac{3}{\sqrt 6}$  & $\frac{2}{\sqrt 6}$  \\
sign                                 & $\frac{1}{\sqrt 6}$ & $-\frac{3}{\sqrt 6}$ & $\frac{2}{\sqrt 6}$  \\
$U/V$ & $\frac{2}{\sqrt 6}$ & 0                    & $-\frac{2}{\sqrt 6}$
\end{tabular}
\end{table}
\end{example}

\begin{prop}
\label{prop:onRimponC}
A matrix $A$ with orthonormal rows also has orthonormal columns.
\end{prop}
\begin{proof}
For a matrix $A$ with orthonormal rows, let $A^\dagger$ denote its conjugate transpose. One has
\[
(AA^\dagger)_{i,j}=\sum_{l=1}^k A_{i,l}A^\dagger_{l,j}=\sum_{l=1}^k A_{i,l} \overline{A_{j,l}}=\la A_{\text{row }i},A_{\text{row }j}\ra=\delta_{i,j},
\]
so $A^\dagger=A^{-1}$. But conversely,
\[
\delta_{i,j}=(A^{-1}A)_{i,j}=(A^\dagger A)_{i,j}=\la A^\dagger_{\text{row }i},A^\dagger_{\text{row }j} \ra=\la \overline{A_{\text{col }i}},\overline{A_{\text{col }j}} \ra=\la A_{\text{col }i},A_{\text{col }j} \ra.
\]
\end{proof}
\begin{defn}
Matrices $A$ with $A^\dagger=A^{-1}$ are \textit{unitary}.
\end{defn}
\begin{coro}[Orthogonal columns]
\[
\forall g\in G,\ \sum_\chi \chi(g)\overline{\chi(g)}=\frac{|G|}{|\Cl_G(g)|}
\]
where the sum is over all irreducible characters $\chi$. If $g_1$ and $g_2$ are not conjugates then
\[
\sum_\chi \chi(g_1)\overline{\chi(g_2)}=0.
\]
\end{coro}
\begin{proof}
Rescaling every column of the character table $T$ by $\sqrt{\frac{|\Cl_G(g)|}{|G|}}$ gives a matrix $A$ with orthonormal rows by \ref{thm:orthogonalityrelations}, hence orthonormal columns by \ref{prop:onRimponC}.
\end{proof}

\subsection{The isotypic decomposition}
\begin{thm}
\label{thm:isotypicdecomp}
Let $W_1,\ldots,W_k$ be a complete list of pairwise nonisomorphic irreducibles of $G$. For a fixed $i\in\{1,\ldots,k\}$, let
\[
a_i:=\frac{\dim W_i}{|G|}\sum_{g\in G}\overline{\chi_{W_i}(g)}g \in\C G.
\]
and let $V\in\Mod G$. Consider the decomposition into irreducibles
\[
V=\bigoplus_{l=1}^k \underbrace{\bigoplus_{j=1}^{\mult_{W_l}(V)} U_{l,j}}_{V_l}\qquad\text{with each }U_{l,j}\sim W_l.
\]
Then $\rho_V(a_i)\in\End(V)$ is the projection onto $V_i$. In particular, the space $V_i$ is independent of the finer decomposition of $V$ into the $U_{l,j}$.
\end{thm}

\begin{flushright}
\textit{Week 7, lecture 1 starts here}
\end{flushright}

\begin{proof}
Fix $i\in\{1,\ldots,k\}$ and let $U\in\Mod G$ be irreducible such that $U\sim W_j$. Consider $\rho_U(a_i)\in\End(U)$. We claim $a_i\in Z(\C G)$. Indeed, for $h\in G,$
\[
\begin{aligned}
ha_i&=h\frac{\dim W_i}{|G|}\sum_{g\in G}\overline{\chi_{W_i}(g)}g=\frac{\dim W_i}{|G|}\sum_{g\in G}\overline{\chi_{W_i}(g)}hg=\frac{\dim W_i}{|G|}\sum_{g\in G}\overline{\chi_{W_i}(h^{-1}gh)}hh^{-1}gh\\
&=\frac{\dim W_i}{|G|}\sum_{g\in G}\overline{\chi_{W_i}(g)}gh=a_ih,
\end{aligned}
\]
and therefore $\rho_U(h)\rho_U(a_i)=\rho_U(ha_i)=\rho_U(a_ih)=\rho_U(a_i)\rho_U(h)$, i.e. $\rho_U(a_i)\in\End_G(U)$. By \ref{thm:SchurslemmaoverC}, $\rho_U(a_i)=\lambda_{i,j}I_U$ for some $\lambda_{i,j}\in\C$. Note
\[
\lambda_{i,j}\dim U=\tr(\rho_U(a_i))=\frac{\dim W_i}{|G|}\sum_{g\in G}\overline{\chi_{W_i}(g)}\underbrace{\tr(\rho_U(g))}_{\chi_{W_j}(g)}=\dim W_i\la \chi_{W_j},\chi_{W_i}\ra=\dim W_i\delta_{i,j},
\]
and note that if $i=j$ then $\dim U=\dim W_j=\dim W_i$, so $\lambda_{i,j}=\delta_{i,j}$.

Hence, if we take a basis of $V$ that respects the decomposition
\[
V=\bigoplus_{l=1}^k\bigoplus_{j=1}^{\mult_{W_l}(V)} U_{l,j},
\]
then $\rho_V(a_i)$ is a block diagonal matrix, one block for each $U_{l,j}$ and it is the zero matrix for all $i\neq l$ and is identity for all $U_{i,j}$. This is the projection to $\bigoplus_j U_{i,j}=V_i$.
\end{proof}

\begin{example}
For $W_0$ being the trivial representation, one has
\[
a_0=\frac{1}{|G|}\sum_{g\in G}g\in\C G,
\]
the projection to the invariant space.
\end{example}
\begin{example}
Let $G=C_2=\la x\mid x^2=1\ra,\ V=\C^{2\times 2}$ with the action $xA=A^T$. Then
\[
a_{\text{triv}}=\frac12(1+x),\qquad a_{\text{sign}}=\frac12(1-x)
\]
so in particular if $A$ is symmetric then $a_{\text{triv}}A=\frac12\left(A+A^T\right)=A$ (i.e. the 3-dimensional space of symmetric matrices is invariant under $a_\text{triv}$) and $a_{\text{sign}}A=\frac12\left(A-A^T\right)=0$. But if $B$ is any matrix then $a_{\text{triv}}B$ will be symmetric, so $a_{\text{triv}}$ is idempotent, hence a projection. Similar for $a_\text{sign}$, it's a projection to the 1-dimensional space of skew-symmetric matrices (matrices of the form $\begin{pmatrix}0&a\\-a&0\end{pmatrix}$).
\end{example}

\begin{defn}
Theorem \ref{thm:isotypicdecomp} gives a decomposition $V=\bigoplus_{i=1}^k V_i$. We call $V_i$ an \textit{isotypic component}, which are unique up to reordering of the summands. A representation that contains only on nonzero isotypic component is \textit{isotypic}.
\end{defn}

\begin{flushright}
\textit{Week 7, lecture 2 starts here}
\end{flushright}

\section{Induced representation}
\begin{defn}
Let $H\leq G$ be a subgroup and let $V\in\Mod G$. Then $H$ acts linearly on $V$ and we denote the corresponding $\C H$-module by $V\downarrow_H^G\in\Mod H$, called the \textit{restriction} of $V$.

We write $\chi_V\downarrow_H^G:=\chi_{V\downarrow_H^G}$.
\end{defn}
Note that if $V\in\Mod G$ is irreducible then $V\downarrow_H^G$ might not be irreducible. For example, if $\dim V=2$ and $H=\{e\}$ is the trivial group.

In the following, let $H\leq G$ and fix a set of coset representatives $t_1,\ldots,t_l:G=t_1H\sqcup t_2H\sqcup\cdots\sqcup t_lH$. The set $\{t_1,\ldots,t_l\}$ is called a \textit{transversal}.

\begin{defn}[The coset module]
Let $\cH=\{t_1H,\ldots,t_l H\}$. The group $G$ acts on $\cH$ via $g(t_i H):=(gt_i)H$.

Let $\C\cH\in\Mod G$ denote the corresponding permutation representation, called the coset module.
\end{defn}

\begin{example}
Let $G=S_3,\ H=\{\id,(23)\}$ and $\cH=\{H,(12)H,(13)H\}$. Then
\[
\C\cH=\{\alpha_1 H+\alpha_2(12)H+\alpha_3(13)H:\alpha_1,\alpha_2,\alpha_3\in\C\}.
\]
We determine $\rho_{\C\cH}((12))\in GL_3(\C)$ with respect to the basis $\cH$:
\[
\begin{aligned}
(12)H&=(12)H\\
(12)(12)H&=H\\
(12)(13)H=(132)H=(132)(23)H&=(13)H
\end{aligned}
\]
since $(23)\in H$, so the matrix is
\[
\begin{pmatrix}
0&1&0\\1&0&0\\0&0&1
\end{pmatrix}.
\]
\end{example}

\begin{defn}
If $\rho:H\rightarrow GL_n(\C)$ is a $H$-representation, define $\rho\uparrow_H^G:G\rightarrow \End(\C^{nl})$ via
\[
\rho\uparrow_H^G(g):=\begin{pmatrix}
\rho(t_1^{-1}gt_1) & \cdots & \rho(t_1^{-1}gt_l) \\
\vdots & \ddots & \vdots \\
\rho(t_l^{-1}gt_1) & \cdots & \rho(t_l^{-1}gt_l)
\end{pmatrix}
\]
where $\rho(g)=0$ if $g\notin H$.

$\rho\uparrow_H^G$ is called the \textit{induced representation} of $\rho$.
\end{defn}

\begin{prop}
\label{prop:trivinduced}
Let $1:H\rightarrow GL_1(\C)$ denote the trivial representation of $H$. Then $1\uparrow_H^G\in\Mod G$ and one has $1\uparrow_H^G\sim\C\cH$.
\end{prop}
\begin{proof}
Let $\rho:=\rho_{1\uparrow_H^G}$ and $\psi:=\rho_{\C\cH}$. We claim that $\forall g\in G,\ \rho(g)=\psi(g)$. Note $\forall g\in G$, both $\rho(g)$ and $\psi(g)$ contain only 0s and 1s. Now $\forall g\in G$:
\[
\rho(g)_{i,j}=1\iff t_i^{-1}gt_j\in H\iff g(t_jH)=t_iH\iff \psi(g)_{i,j}=1.
\]
\end{proof}

\begin{thm}
$\rho\uparrow_H^G:G\rightarrow GL_{nl}(\C)$ is a matrix representation.
\end{thm}
\begin{proof}
We prove that $\rho\uparrow_H^G(g)$ is a block matrix whose coarse structure is a permutation matrix, i.e. in every row and column of blocks there is exactly one nonzero block. Now for the $j$th column, the blocks are $\rho(t_1^{-1}gt_j),\rho(t_2^{-1}gt_j),\ldots,\rho(t_l^{-1}gt_j)$. But $t_i^{-1}gt_j\in H\iff gt_j\in t_iH$ which is true for exactly one $i$ since the $t_iH$'s form a disjoint union of $G$. Analogously for rows. It's also easy to check $\rho\uparrow_H^G(e)=I_{nl}$ since $t_i^{-1}t_j\in H\iff t_j\in t_iH\iff i=j$. It remains to prove $\forall g,h\in G$,
\[
\rho\uparrow_H^G(gh)=\rho\uparrow_H^G(g)\rho\uparrow_H^G(h).
\]
Consider the $(i,j)$th block on both sides, it suffices to prove
\[
\tag{$\ast$}
\sum_{k=1}^l\rho(\underbrace{t_i^{-1}gt_k}_{a_k})\rho(\underbrace{t_k^{-1}ht_j}_{b_k})=\rho(\underbrace{t_i^{-1}ght_j}_{c}).
\]

\begin{flushright}
\textit{Week 7, lecture 3 starts here}
\end{flushright}

Note $\forall k,\ a_kb_k=t_i^{-1}gt_kt_k^{-1}ht_j=t_i^{-1}ght_j=c$.

If $\rho(c)=0$ then $c\notin H$ so either $a_k\notin H$ or $b_k\notin H \ \forall k$, i.e. $\rho(a_k)=0$ or $\rho(b_k)=0 \ \forall k$, thus $\sum_k \rho(a_k)\rho(b_k)=0$, which proves $\ast$.

If $\rho(c)\neq 0$ then let $m$ be the unique index with $a_m\in H$ (see previous block structure argument), then $b_m=a_m^{-1}c\in H$ and $\sum_k \rho(a_k)\rho(b_k)=\rho(a_m)\rho(b_m)=\rho(a_mb_m)=\rho(c)$ since $\rho$ is representation of $H$.
\end{proof}

\begin{thm}
\label{thm:diffcosetrepindisorep}
A priori the construction process of $\rho\uparrow_H^G$ depends on the set of coset representations. Consider $\rho\uparrow_H^{G,t}$ and $\rho\uparrow_H^{G,s}$ constructed from $\rho:H\rightarrow GL(V)$ using two sets of coset representations $t=(t_1,\ldots,t_l)$ and $s=(s_1,\ldots,s_l)$ respectively:
\[
G=t_1 H\sqcup\cdots\sqcup t_lH=s_1 H\sqcup\cdots\sqcup s_lH,
\]
then $\rho\uparrow_H^{G,t}\sim\rho\uparrow_H^{G,s}$.
\end{thm}
\begin{proof}
By \ref{coro:convisorepcharsame} it suffices to show $\chi\uparrow_H^{G,t}=\chi\uparrow_H^{G,s}$. One has
\[
\tag{\ref{thm:diffcosetrepindisorep}.1}
\chi\uparrow_H^{G,t}=\sum_{i=1}^l \tr(\rho(t_i^{-1}gt_i))=\sum_{i=1}^l \chi(t_i^{-1}gt_i)
\]
and similarly
\[
\tag{\ref{thm:diffcosetrepindisorep}.2}
\chi\uparrow_H^{G,s}=\sum_{i=1}^l \chi(s_i^{-1}gs_i).
\]
Now note that $t_iH=s_iH \ \forall i$ (after relabelling), which implies $\forall i,\ \exists h_i\in H:t_i=s_ih_i$, so
\[
t_i^{-1}gt_i=h_i^{-1}s_i^{-1}gs_ih_i,
\]
which means
\begin{itemize}
\item $t_i^{-1}gt_i\in H$ iff $s_i^{-1}gs_i\in H$
\item when both in $H$, they are conjugate
\end{itemize}
Hence $\chi(t_i^{-1}gt_i)=\chi(s_i^{-1}gs_i)$.
\end{proof}

\begin{lemma}
\label{lemma:formulaforcharofindrep}
Let $\rho\in\Mod H$ with character $\chi$. Then
\[
\chi\uparrow_H^G(g)=\frac{1}{|H|}\sum_{x\in G}\chi(x^{-1}gx)
\]
where $\chi(g)=0$ if $g\notin H$.
\end{lemma}
\begin{proof}
Cf. proof of \ref{thm:diffcosetrepindisorep}. Observe
\[
\chi(t_i^{-1}gt_i)=\frac{1}{|H|}\sum_{h\in H}(h^{-1}t_i^{-1}gt_ih)
\]
which, plugged into \ref{thm:diffcosetrepindisorep}.1, gives
\[
\chi\uparrow_H^G(g)=\frac{1}{|H|}\sum_{i\in\{1,\ldots,l\},h\in H}\chi(h^{-1}t_i^{-1}gt_ih)
\]
but by going through all the $i$'s (all the cosets) and $h\in H$ (all elements in the subgroup), $t_ih$ gives us precisely all elements of $G$, hence
\[
\chi\uparrow_H^G(g)=\frac{1}{|H|}\sum_{x\in G}\chi(x^{-1}gx).
\]
\end{proof}

\begin{thm}[Frobenius reciprocity]
Let $H\leq G$ and let $\psi,\chi$ be characters of $H$ and $G$ respectively. Then
\[
\la\psi\uparrow_H^G,\chi\ra=\la\psi,\chi\downarrow_H^G\ra.
\]
\end{thm}
\begin{proof}
\[
\begin{aligned}
\la\psi\uparrow_H^G,\chi\ra&=\frac{1}{|G|}\sum_{g\in G}\psi\uparrow_H^G(g)\chi(g^{-1}) \\
&=\frac{1}{|G|\cdot|H|}\sum_{x\in G}\sum_{g\in G}\psi(x^{-1}gx)\chi(g^{-1}) \qquad \text{by \ref{lemma:formulaforcharofindrep}}\\
&=\frac{1}{|G|\cdot|H|}\sum_{x\in G}\sum_{y\in G} \psi(y)\chi(xy^{-1}x^{-1})\qquad\text{writing }y=x^{-1}gx\\
&=\frac{1}{|G|\cdot|H|}\sum_{x\in G}\sum_{y\in G} \psi(y)\chi(y^{-1})\qquad\text{by \ref{prop:1stpropofchar}.4}\\
&=\frac{1}{|G|\cdot|H|}|G|\sum_{y\in G}\psi(y)\chi(y^{-1})=\frac{1}{|H|}\sum_{y\in G}\psi(y)\chi(y^{-1}) \qquad\text{independence of }x\\
&=\frac{1}{|H|}\sum_{y\in H}\psi(y)\chi(y^{-1}) \qquad\text{since }\psi(y)=0\text{ if } y\notin H\\
&=\la\psi,\chi\downarrow_H^G\ra.
\end{aligned}
\]
\end{proof}

\section{An in-depth example: the symmetric group $S_n$}
\subsection{Young subgroup, tableau, tabloid}
\begin{defn}
A \textit{partition} $\lambda$ of $n$ is a list $(\lambda_1,\ldots,\lambda_l)\in\N^l$ with $\lambda_1\geq\cdots\geq\lambda_l>0$ with $\sum_{i=1}^l \lambda_i=n$. One writes $\lambda\vdash n$. The number $l(\lambda)=l$ is the \textit{length} of $\lambda$ and $\lambda_i=0$ for $i>l(\lambda)$.
\end{defn}

\begin{flushright}
\textit{Week 8, lecture 1 starts here}
\end{flushright}

We have seen that \# conjugacy classes in $S_n=$ \# partitions of $n$.

\begin{defn}
For each partition $\lambda$ we can draw its \textit{Ferrers (or Young) diagram}, for example for $\lambda=(3,3,2,1)$ (or $(3^2,2,1)$) the diagram is \ydiagram{3,3,2,1}.
\end{defn}

\begin{notation}
For a set $A$ write $S_A:=\{\pi:A\rightarrow A\text{ bijective}\}$. In particular $S_n=S_{\{1,\ldots,n\}}$.
\end{notation}

\begin{defn}
Let $\lambda\vdash n$. The $\textit{Young subgroup}$ $S_\lambda\leq S_n$ is
\[
S_\lambda=S_{\{1,2,\ldots,\lambda_1\}}\times S_{\{\lambda_1+1,\ldots,\lambda_1+\lambda_2\}}\times\cdots\times S_{\{n-\lambda_l+1,\ldots,n\}}.
\]
\end{defn}
\begin{example}
\[
S_{\{3,3,2,1\}}=S_{\{1,2,3\}}\times S_{\{4,5,6\}}\times S_{\{7,8\}}\times S_{\{9\}}.
\]

In general,
\[
S_\lambda\cong S_{\lambda_1}\times S_{\lambda_2}\times\cdots\times S_{\lambda_l}.
\]
\end{example}

Now consider $1\uparrow_{S_\lambda}^{S_n}$. If $\pi_1,\ldots,\pi_k$ is a transversal, then $S_n$ acts linearly on
\[
V^\lambda=\linspan\{\pi_1 S_\lambda,\ldots,\pi_k S_\lambda\}
\]
and one has $V^\lambda\sim 1\uparrow_{S_\lambda}^{S_n}$. See \ref{prop:trivinduced}.

\begin{defn}
Let $\lambda\vdash n$. A \textit{Young tableau} (or just \textit{tableau}) $t$ of shape $\lambda$ is an array obtained by writing numbers $1,2,\ldots,n$ into the boxes of the Young diagram of $\lambda$, each number exactly once.

The shape $\sh(t)$ of a Young tableau is the partition associated to its Young diagram, e.g.
\[
\sh\left(\begin{ytableau}
  2&1&4\\5&3
\end{ytableau}\right)=(3,2).
\]
A Young tableau of shape $\lambda$ is also called a $\lambda$-tableau. For $\lambda\vdash n$ there are $n!$ $\lambda$-tableaux.

Let $t_{i,j}$ denote the entry of $t$ at position $i,j$.
\end{defn}

\begin{defn}
Two $\lambda$-tableaux are \textit{row-equivalent}, denoted $t_1\sim t_2$, if the corresponding rows contain the same elements. An equivalence class of this is a \textit{tabloid} of shape $\lambda$ or $\lambda$-tabloid, denoted $\{t_1\}$ (so $t_1\sim t_2\implies \{t_1\}=\{t_2\}$). We use lines between rows to denote tabloids:
\[
\ytableausetup{tabloids}
\begin{ytableau}
  2&1&4\\5&3
\end{ytableau}=\begin{ytableau}
  4&2&1\\5&3
\end{ytableau}=\begin{ytableau}
  1&2&4\\3&5
\end{ytableau}=\cdots
\]
\end{defn}

$\pi\in S_n$ acts on a Young tableau $t$ via $(\pi t)_{i,j}=\pi(t_{i,j})$, which induces an action on tabloids also: $\pi\{t\}=\{\pi t\}$.

\begin{defn}
Let $\lambda\vdash n$ and $\{t_1\},\ldots,\{t_k\}$ a complete list of $\lambda$-tabloids. Define
\[
M^\lambda:=\linspan\{ \{t_1\},\ldots,\{t_k\} \},
\]
the \textit{permutation module} corresponding to $\lambda$.
\end{defn}

\begin{example}
Consider $\lambda=(n)$, giving one-row Young tableaux. Then $M^{(n)}=\C\left\{\begin{ytableau}
  1&2&\cdots&n
\end{ytableau}\right\}$ with the trivial action.

Now consider $\lambda=(1^n)$, giving one-column Young tableaux. Then $M^{(1^n)}\sim\C S_n$.

Let $\lambda=(n-1,1)$. Then each tabloid is uniquely defined by the entry at position $(2,1)$, hence $M^{(n-1,1)}$ is isomorphic to the permutation representation of $S_n$ on the set $\{1,2,\ldots,n\}$ defined via $\pi\cdot i=\pi(i)$.
\end{example}

\begin{prop}
$M^\lambda\sim V^\lambda$.
\end{prop}
\begin{proof}
Fix the Young tableau $t^\lambda$ that has row-wise consecutive increasing numbers from left to right, e.g.
\[
\ytableausetup{notabloids}
t^{(4,2,1)}=\begin{ytableau}
  1&2&3&4\\5&6\\7
\end{ytableau}
\]
and let $\pi_1,\ldots,\pi_k$ be a transversal for $S_\lambda$. Define $\theta:V^\lambda\rightarrow M^\lambda:\pi_i S_\lambda\mapsto \pi_i t^\lambda$. It is easy to verify that $\theta$ is an isomorphism of $S_n$-representations.
\end{proof}

\begin{flushright}
\textit{Week 8, lecture 2 starts here}
\end{flushright}

\subsection{Dominance and lexicographic ordering}
\begin{defn}
A \textit{partial order} on a set $A$ is a relation $\leq$ such that
\begin{enumerate}
\item $\forall a\in A,\ a\leq a$\hfill reflexivity
\item $\forall a,b\in A,\ a\leq b,b\leq a\implies a=b$\hfill antisymmetry
\item $\forall a,b,c\in A,\ a\leq b,b\leq c\implies a\leq c$\hfill transitivity
\end{enumerate}
and one says $A$ is a \textit{partially ordered set}, or \textit{poset}. If in addition $\forall a,b\in A$ either $a\leq b$ or $b\leq a$, then $\leq$ is a \textit{total order}.
\end{defn}

\begin{defn}
Let $\lambda,\mu\vdash n$. Then $\lambda$ \textit{dominates} $\mu$, denoted $\lambda\unrhd \mu$, if
\[
\forall k,\ \sum_{i=1}^k \lambda_i\geq \sum_{i=1}^k \mu_i.
\]
For example, $(3,3)\unrhd (2,2,1,1)$. Note it's not a total order, e.g. $(3,3)$ and $(4,1,1)$ are incomparable.
\end{defn}

\begin{defn}
Let $A$ be a poset. For $b,c\in A$, one says $c$ \textit{covers} $b$ if $c>b$ (meaning $c\geq b$ and $c\neq b$) and $\nexists d\in A:b<d<c$.

The \textit{Hasse diagram} consists of
\begin{itemize}
\item a vertex for each $a\in A$
\item an arrow from $b$ to $c$ if $c$ covers $b$
\end{itemize}
For example,

\[
\xymatrix@R=1.5em{
  &(6)\\
  &(5,1)\ar[u]\\
  &(4,2)\ar[u]\\
  (3^2)\ar[ur] & & (4,1^2)\ar[ul]\\
  &(3,2,1)\ar[ur]\ar[ul]\\
  (3,1^3)\ar[ur] & & (2^3)\ar[ul]\\
  &(2^2,1^2)\ar[ul]\ar[ur]\\
  &(2,1^4)\ar[u]\\
  &(1^6)\ar[u]
}
\]
\end{defn}

\begin{lemma}[Dominance lemma for partitions]
\label{lemma:dompart}
Let $\lambda,\mu\vdash n$ and $t^\lambda$ and $s^\mu$ be Young tableaux of shape $\lambda$ and $\mu$ respectively. If for each $i$ the elements of row $i$ of $s^\mu$ are all in different columns in $t^\lambda$, then $\lambda\unrhd\mu$.
\end{lemma}
\begin{proof}
We can sort the entries in each column of $t^\lambda$ so that the elements of the rows $1,2,\ldots,i$ of $s^\mu$ all occur in the first $i$ rows of $t^\lambda$. Let $E_i(t)$ denote the set of elements in the first $i$ rows of $t$. Then
\[
\lambda_1+\lambda_2+\cdots+\lambda_i=|E_i(t^\lambda)|\geq |E_i(t^\lambda)\cap E_i(s^\mu)|=|E_i(s^\mu)|=\mu_1+\mu_2+\cdots+\mu_i,
\]
i.e. $\lambda\unrhd\mu$.
\end{proof}

\begin{defn}
Let $\lambda,\mu\vdash n$. One writes $\lambda<\mu$ if one has for some $i$
\begin{enumerate}
\item $\forall j<i,\ \lambda_j=\mu_j$
\item $\lambda_i<\mu_i$
\end{enumerate}
This is the \textit{lexicographic order}, which is a total order.

For example, $(1^6)<(2,1^4)<(2^2,1^2)<(2^3)<(3,1^3)<(3,1,2)<(3,3)<(4,1^2)<(4,2)<(5,1)<(6)$.
\end{defn}

\begin{prop}[Lexicographic order is a refinement of dominance]
Let $\lambda,\mu\vdash n$. If $\lambda\unrhd\mu$ then $\lambda\geq\mu$.
\end{prop}
\begin{proof}
If $\lambda=\mu$ then we are done, so suppose $\lambda\neq\mu$ and find the smallest $i$ with $\lambda_i\neq\mu_i$, so in particular $\forall k<i,\ \sum_{j=1}^k \lambda_j=\sum_{j=1}^k\mu_j$ and since $\lambda\unrhd\mu$ one has $\sum_{j=1}^i \lambda_j>\sum_{j=1}^i\mu_j$, so $\lambda_i>\mu_i$ and hence $\lambda>\mu$.
\end{proof}

\subsection{Specht module}
\begin{defn}
For a tableaux $t$ with rows $R_1,\ldots,R_l$ and columns $C_1,\ldots,C_k$, define the \textit{row-stabiliser}
\[
R_t:=S_{R_1}\times S_{R_2}\times\cdots\times S_{R_l}
\]
and the \textit{column-stabiliser}
\[
C_t:=S_{C_1}\times\cdots\times S_{C_k}.
\]
\end{defn}
\begin{example}
For $t=\begin{ytableau}
4&1&2\\3&5
\end{ytableau}$, one has $R_t=S_{\{1,2,4\}}\times S_{\{3,5\}}$ and $C_t=S_{\{3,4\}}\times S_{\{1,5\}}\times S_{\{2\}}$.
\end{example}

\begin{flushright}
\textit{Week 8, lecture 3 starts here}
\end{flushright}

\begin{remark}
Note that we can identify the tabloid $\{t\}$ with the right coset $R_tt$.
\end{remark}

\begin{notation}
For any subset $H\subseteq S_n$, define the elements in the group algebra
\[
H^+ := \sum_{\pi\in H}\pi,\qquad H^- := \sum_{\pi\in H}\sgn(\pi)\pi,
\]
in particular, define $\kappa_t:=C_t^-$.
\end{notation}
Observe that if $t$ has columns $C_1,\ldots,C_k$, then $\kappa_t=\kappa_{C_1}\kappa_{C_2}\cdots \kappa_{C_k}$.

\begin{defn}
For a tableau $t$ of shape $\lambda$, the \textit{associated polytabloid} $e_t\in M^\lambda$ is $e_t:=\kappa_t \{t\}$.
\end{defn}

\begin{example}
For $t=\begin{ytableau}
4&1&2\\3&5
\end{ytableau}$, one has
\[
\kappa_t=(\id-(3,4))(\id-(1,5))=\id-(3,4)-(1,5)+(3,4)(1,5),
\]
so
\[
\begin{aligned}
\ytableausetup{tabloids}
e_t&=\begin{ytableau}
  4&1&2\\3&5
\end{ytableau}-\begin{ytableau}
  3&1&2\\4&5
\end{ytableau}-\begin{ytableau}
  4&5&2\\3&1
\end{ytableau}+\begin{ytableau}
  3&5&2\\4&1
\end{ytableau}\\
&=\begin{ytableau}
  1&2&4\\3&5
\end{ytableau}-\begin{ytableau}
  1&2&3\\4&5
\end{ytableau}-\begin{ytableau}
  2&4&5\\1&3
\end{ytableau}+\begin{ytableau}
  2&3&5\\1&4
\end{ytableau}.
\end{aligned}
\]
\end{example}

\begin{defn}
For any partition $\lambda$, the \textit{Specht module} $S^\lambda$ is defined as the submodule of $M^\lambda$ spanned by the polytabloids $e_t$ where $\sh(t)=\lambda$.
\end{defn}

\begin{lemma}
\label{lemma:tabpermformulae}
Let $t$ be a tableau and $\pi$ a permutation. Then
\begin{enumerate}
\item $R_{\pi t}=\pi R_t \pi^{-1}$
\item $C_{\pi t}=\pi C_t \pi^{-1}$
\item $\kappa_{\pi t}=\pi\kappa_t \pi^{-1}$
\item $e_{\pi t}=\pi e_t$
\end{enumerate}
\end{lemma}
\begin{proof}
\begin{enumerate}
\item $\sigma\in R_{\pi t}\iff\sigma\{\pi t\}=\{\pi t\}\iff\sigma\pi\{t\}=\pi\{t\}\iff\pi^{-1}\sigma\pi\{t\}=\{t\}\iff\pi^{-1}\sigma\pi\in R_t\iff \sigma\in\pi R_t\pi^{-1}$.
\item[2, 3.] Similar.
\item[4.] $e_{\pi t}=\kappa_{\pi t}\{\pi t\}=\pi\kappa_t\pi^{-1}\{\pi t\}=\pi\kappa_t\{t\}=\pi e_t$.
\end{enumerate}
\end{proof}

\begin{example}
$S^{(n)}\subseteq M^{(n)}$ is the trivial representation.
\end{example}

\begin{example}
\label{example:1colsignrep}
Let $\lambda=(1^n)$ and $\ytableausetup{notabloids} t=\begin{ytableau}
1\\2\\ \vdots\\n
\end{ytableau}$. Then $\kappa_t=\sum_{\sigma\in S_n}\sgn(\sigma)\sigma$. For $\pi\in S_n$, by Lemma \ref{lemma:tabpermformulae} one has
\[
e_{\pi t}=\pi e_t=\sum_{\sigma\in G}\sgn(\sigma)\pi\sigma\{t\},
\]
replacing $\pi\sigma$ by $\tau$ one has
\[
e_{\pi t}=\sum_{\tau\in S_n} \sgn(\pi^{-1}\tau)\tau\{t\}=\sgn(\pi^{-1})\sum_{\tau\in S_n}\sgn(\tau)\tau\{t\}=\sgn(\pi)e_t,
\]
thus every polytabloid is a multiple of $e_t$, hence $S^{(1^n)}=\C e_t$ and $\pi e_t=\sgn(\pi)e_t$ (therefore this is the sign representation).
\end{example}

\begin{example}
Let $\lambda=(n-1,1),\ t_k=\begin{ytableau}i&\cdots & j\\k\end{ytableau}$ and $v_k=\{t_k\}$. Then $e_t=v_k-v_i$ and the span of all such vectors is
\[
S^{(n-1,1)}=\{\alpha_1 v_1+\cdots+\alpha_n v_n : \alpha_1+\cdots+\alpha_n=0,\alpha_i\in\C\}.
\]
This is the kernel of Example \ref{example:S3perm}.
\end{example}

\begin{flushright}
\textit{Week 9, lecture 1 starts here}
\end{flushright}

\subsection{The submodule theorem}
\begin{defn}
Define inner product on $M^\lambda$ via
\[
\la \{t\},\{s\}\ra := S_{\{t\},\{s\}}.
\]
Note that $\forall\pi\in S_n$ one has $\la \{t\},\{s\}\ra=\la \pi\{t\},\pi\{s\}\ra$ and hence $\forall u,v\in M^\lambda, \la u,v\ra=\la \pi u,\pi v\ra$.
\end{defn}

\begin{notation}
$\pi^-:=\{\pi\}^-=\sgn(\pi)\pi$.
\end{notation}

\begin{lemma}[Sign]
\label{lemma:sign}
Let $H\leq S_n$ be a subgroup. Then
\begin{enumerate}
\item If $\pi\in H$ then $\pi H^-=H^-\pi=\sgn(\pi)H^-$, i.e. $\pi^-H^-=H^-$.
\item $\forall u,v\in M^\lambda,\ \la H^-u,v\ra=\la u,H^-v\ra$.
\item If $(b,c)\in H$ then one can factor $H^-=k\cdot (\id-(b,c))$ for some $k\in\C S_n$.
\item If $t$ is a tableau with $b,c$ in the same row and $(b,c)\in H$ then $H^-\{t\}=0$.
\end{enumerate}
\end{lemma}
\begin{proof}
\begin{enumerate}
\item Similar to $\pi e_t=\sgn(\pi)e_t$ in \ref{example:1colsignrep}:
\[
\pi H^-=\sum_{\sigma\in H}\sgn(\sigma)\pi\sigma=\sum_{\tau\in H}\sgn(\pi^{-1}\tau)\tau=\sgn(\pi^{-1})\sum_{\tau\in H} \sgn(\tau)\tau=\sgn(\pi)H^-.
\]
\item \[
\begin{aligned}
\la H^-u,v \ra&=\sum_{\pi\in H}\la \sgn(\pi)\pi u,v \ra=\sum_{\pi\in H}\la\sgn(\pi)u,\pi^{-1}v\ra\\
&=\sum_{\pi\in H}\la u,\sgn(\pi^{-1}),\pi^{-1}v\ra=\sum_{\pi\in H}\la u,\sgn(\pi)\pi v\ra=\la u,H^-,v\ra.
\end{aligned}
\]
\item Consider the subgroup $\{\id,(b,c)\}\leq H$. Take a transversal
\[
k_1\{\id,(b,c)\}\sqcup k_2\{\id,(b,c)\}\sqcup\cdots\sqcup\cdots
\]
Observe
\[
\left(\sum_i k_i^-\right)(\id-(b,c))=H^-
\]
as desired.
\item By assumption, $(b,c)\{t\}=\{t\}$, so
\[
H^-\{t\}=k\cdot(\id-(b,c))\{t\}=0.
\]
\end{enumerate}
\end{proof}

\begin{coro}
\label{coro:non0kappameansdominance}
Let $\lambda,\mu\vdash n$ and $t$ a $\lambda$-tableau and $s$ a $\mu$-tableau. If $\kappa_t\{s\}\neq 0$ then $\lambda\unrhd\mu$ and if $\lambda=\mu$ then $\kappa_t\{s\}\in\{-e_t,e_t\}$.
\end{coro}
\begin{proof}
Let $b,c$ be two elements in the same row of $s$. If they are also in the same column of $t$ then by \ref{lemma:sign}.4 $\kappa_t\{s\}=0$. If not then \ref{lemma:dompart} gives $\lambda\unrhd\mu$.

If additionally $\lambda=\mu$ then by the same argument one can reorder within columns of $t$, i.e. $\exists\pi\in C_t: \{s\}=\pi\{t\}$, and \ref{lemma:sign}.1 gives $\kappa_t\{s\}=\kappa_t\pi\{t\}=\sgn(\pi)\kappa_t\{t\}\in\{\pm e_t\}$.
\end{proof}

\begin{coro}
\label{coro:kappatuismultofet}
If $u\in M^\mu$ and $\sh(t)=\mu$ then $\kappa_t u$ is a multiple of $e_t$.
\end{coro}
\begin{proof}
Write $u=\sum_i\alpha_i\{s_i\}$ where $\{s_i\}$ are $\mu$-tabloids. Corollary \ref{coro:non0kappameansdominance} gives
\[
\kappa_t u=\kappa_t \sum_i \alpha_i\{s_i\}=\sum_i\alpha_i\kappa_t\{s_i\}=\left(\sum_i\pm \alpha_i\right) e_t.
\]
\end{proof}

\begin{flushright}
\textit{Week 9, lecture 2 starts here}
\end{flushright}

\begin{notation}
For a linear subspace $U\subseteq M^\mu$, define
\[
U^\perp :=\{v\in M^\mu:\la u,v\ra=0 \ \forall u\in U\}.
\]
\end{notation}

\begin{thm}[Submodule]
\label{thm:submodule}
If $U\subseteq M^\mu$ is a submodule then $S^\mu\subseteq U$ or $U\subseteq (S^\mu)^\perp$.
\end{thm}
\begin{proof}
For all $u\in U$ and a $\mu$-tableau $t$ we know $\exists\alpha_{u,t}\in\C:\kappa_t u=\alpha_{u,t}e_t$ by \ref{coro:kappatuismultofet}.
\begin{enumerate}
\item[Case 1:] $\exists u,t:\alpha_{u,t}\neq 0$. Since $u\in U$ one has $\alpha_{u,t}e_t=\kappa_t u\in U$, hence $e_t=\alpha_{u,t}^{-1}\kappa_t u\in U$. Therefore $\forall\pi\in S_n,\ e_{\pi t}=\pi e_t\in U$ and so $S^\mu\subseteq U$.
\item[Case 2:] $\alpha_{u,t}=0 \ \forall u,t$. The $e_t$ with $\sh(t)=\mu$ spans $S^\mu$. Let $u\in U$, then
\[
\begin{aligned}
\la u,e_t\ra&=\la u,\kappa_t\{t\}\ra\\
&=\la\kappa_t u,\{t\}\ra \qquad \text{by \ref{lemma:sign}.2}\\
&=\la 0,\{t\}\ra=0.
\end{aligned}
\]
\end{enumerate}
\end{proof}

\begin{prop}
\label{prop:non0homSlamMmumeansdom}
If $0\neq f\in \Hom_{S_n}(S^\lambda,M^\mu)$ then $\lambda\unrhd\mu$. If $\lambda=\mu$ then $f$ is multiplication by a scalar.
\end{prop}
\begin{proof}
Since $f\neq 0$ and $S^\lambda$ is generated by the $e_t$, there must be an $e_t:f(e_t)\neq 0$. Now $M^\lambda=S^\lambda\oplus(S^\lambda)^\perp$. Thus we can extend $f$ to an element of $\Hom_{S_n}(M^\lambda,M^\mu)$ by setting $f(v)=0 \ \forall v\in(S^\lambda)^\perp$. Now
\[
\begin{aligned}
0\neq f(e_t)&=f(\kappa_t\{t\})=\kappa_t f(\{t\})=\kappa_t\sum_i\alpha_i\{s_i\}\\
&=\sum_i\alpha_i\kappa_t\{s_i\} \qquad\text{for some }\alpha_i\in\C\text{ and }s_i\text{ are }\mu\text{-tableaux}
\end{aligned}
\]
and $\lambda\unrhd\mu$ by \ref{coro:non0kappameansdominance}.

If $\lambda=\mu$ then by \ref{coro:kappatuismultofet} $f(e_t)=\sum_i\alpha_i\kappa_t\{s_i\}=\alpha e_t$ for some $\alpha\in\C$, so for every $\pi\in S_n,\ f(e_{\pi t})=f(\pi e_t)=\pi f(e_t)=\pi\alpha e_t=\alpha e_{\pi t}$.
\end{proof}

\begin{thm}
The $S^\lambda$ for $\lambda\vdash n$ form a complete list of irreducible $S_n$-representations.
\end{thm}
\begin{proof}
Let $U\subseteq S^\lambda$ be a subrepresentation. By Theorem \ref{thm:submodule}, either $S^\lambda\subseteq U$ or $U\subseteq (S^\lambda)^\perp$, so either $U=S^\lambda$ or $U\subseteq S^\lambda\cap (S^\lambda)^\perp=\{0\}$, i.e. $S^\lambda$ is irreducible.

Since we have the correct number of irreducible representations, it remains to show that they are pairwise nonisomorphic. Suppose $S^\lambda\sim S^\mu$, then there is a nonzero $f\in\Hom_{S_n}(S^\lambda,S^\mu)$ which can be interpreted as $f\in\Hom_{S_n}(S^\lambda,M^\mu)$ since $S^\mu\subseteq M^\mu$. Then by \ref{prop:non0homSlamMmumeansdom} $\lambda\unrhd\mu$. Symmetrically $\mu\unrhd\lambda$, so $\lambda=\mu$.
\end{proof}

\begin{flushright}
\textit{Week 9, lecture 3 starts here}
\end{flushright}

\begin{coro}
\[
M^\mu\sim\bigoplus_{\lambda\unrhd\mu} (S^\lambda)^{\oplus m_{\lambda,\mu}},
\]
with $m_{\mu,\mu}=1 \ \forall \mu$.
\end{coro}
\begin{proof}
If $S^\lambda$ appears in $M^\mu$ with nonzero multiplicity (i.e. $m_{\lambda,\mu}\geq 1$) then there exists an injective $S_n$-homomorphism $f:S^\lambda\rightarrow M^\mu$, so by \ref{prop:non0homSlamMmumeansdom} $\lambda\unrhd\mu$.

Now $m_{\mu,\mu}\geq 1$ by definition of $S^\mu\subseteq M^\mu$. Suppose for contradiction $m_{\mu,\mu}\geq 2$. Then one can take any decomposition of $M^\mu$ into irreducibles
\[
M^\mu=\bigoplus_{\lambda\vdash n,\ \lambda\unrhd\mu} \left(V_{\lambda,1}\oplus V_{\lambda,2}\oplus\cdots\oplus V_{\lambda,m_{\lambda,\mu}}\right) \qquad \text{where } \forall i,\ V_{\lambda,i}\sim S^\lambda.
\]
Take the isomorphism $f_1:S^\mu\rightarrow V_{\mu,1}$ and $f_2:S^\mu\rightarrow V_{\mu,2}$, then
\[
\forall\alpha,\beta\in\C,\ \alpha f_1+\beta f_2\in\Hom_{S_n}(S^\mu,M^\mu)
\]
and in particular, $\dim\Hom{S^n}(S^\mu,M^\mu)\geq 2$. But $\dim\Hom_{S_n}(S^\mu,M^\mu)=1$ by \ref{prop:non0homSlamMmumeansdom}.
\end{proof}

\subsection{Standard tableaux and basis for $S^\lambda$: linear independence}
\begin{defn}
A tableau is \textit{standard} if the rows are increasing from left to right and the columns are increasing from top to bottom. In this case, the corresponding is tabloid and polytabloid are also \textit{standard}.
\end{defn}
e.g. $\begin{ytableau}
1&2&3\\4&6\\5
\end{ytableau}$ is standard but $\begin{ytableau}
1&2&3\\5&4\\6
\end{ytableau}$ is not.

\begin{thm}
\label{thm:etsttisstandardisbasis}
The set $\{e_t:t\text{ is a standard }\lambda\text{-tableau}\}$ is a basis of $S^\lambda$.
\end{thm}
\begin{example}
$S_3,\ \lambda=(2,1)$. Then
\[
e_{\begin{ytableau}1&2\\3\end{ytableau}}=\ytableausetup{tabloids} \begin{ytableau}1&2\\3\end{ytableau}-\begin{ytableau}3&2\\1\end{ytableau}=\begin{ytableau}1&2\\3\end{ytableau}-\begin{ytableau}2&3\\1\end{ytableau},
\]
\[
e_{\ytableausetup{notabloids}\begin{ytableau}2&1\\3\end{ytableau}}=\ytableausetup{tabloids}\begin{ytableau}2&1\\3\end{ytableau}-\begin{ytableau}3&1\\2\end{ytableau}=\begin{ytableau}1&2\\3\end{ytableau}-\begin{ytableau}1&3\\2\end{ytableau},
\]
and
\[
e_{\ytableausetup{notabloids}\begin{ytableau}1&3\\2\end{ytableau}}=\ytableausetup{tabloids}\begin{ytableau}1&3\\2\end{ytableau}-\begin{ytableau}2&3\\1\end{ytableau}.
\]
Now notice that
\[
\ytableausetup{notabloids}
e_{\begin{ytableau}1&2\\3\end{ytableau}}-e_{\begin{ytableau}1&3\\2\end{ytableau}}=e_{\begin{ytableau}2&1\\3\end{ytableau}}
\]
and indeed that $\begin{ytableau}1&2\\3\end{ytableau}$ and $\begin{ytableau}1&3\\2\end{ytableau}$ are standard.
\end{example}

\begin{defn}
A \textit{composition} of $n$ is a sequence of nonnegative integers $(\lambda_1,\ldots,\lambda_l)$ such that $\sum_{i=1}^l \lambda_i=n$. Every partition is a composition.

One extend the notions of Young diagrams/tableaux/tabloids and dominance order to compositions with verbatim definitions, e.g. $(5,3,4,4)\unrhd (4,4,3,5)$.

Given $\{t\}$ with $\sh(t)=\lambda,\ \lambda\vdash n$, for each $i\in\{1,\ldots,n\}$ define
\[
\{t^i\}:=\text{the tabloid formed by all elements} \leq i\text{ in }\{t\}
\]
and
\[
\lambda^i:=\text{the composition that is the shape of }\{t^i\},
\]

e.g. for $\ytableausetup{tabloids} \{t\}=\begin{ytableau}2&4\\1&3\end{ytableau}$,
\[
\{t^1\}=\begin{ytableau}\ \\1\end{ytableau},\quad \{t^2\}=\begin{ytableau}2\\1\end{ytableau},\quad \{t^3\}=\begin{ytableau}2\\1& 3\end{ytableau},\quad \{t^4\}=\begin{ytableau}2&4\\1&3\end{ytableau}
\]
and
\[
\lambda^1=(0,1),\quad \lambda^2=(1,1),\quad \lambda^3=(1,2),\quad \lambda^4=(2,2),
\]
which is called a \textit{composition sequence}.
\end{defn}

\begin{defn}
For two tabloids $\{s\},\{t\}$ with composition sequences $\lambda^i$ and $\mu^i$ respectively. One say $\{s\}$ \textit{dominates} $\{t\}$, denoted $\{s\}\unrhd\{t\}$, if $\forall i,\ \lambda^i\unrhd\mu^i$.
\end{defn}

\begin{example}
The Hasse diagram for $(2,2)$-tabloids:
\[
\xymatrix@R=1.5em{
& & {\begin{ytableau}1&2\\3&4\end{ytableau}} & (1,0),(2,0),(2,1),(2,2) \\
& &{\begin{ytableau}1&3\\2&4\end{ytableau}}\ar[u] & (1,0),(1,1),(2,1),(2,2) \\
(0,1),(1,1),(2,1),(2,2)& {\begin{ytableau}2&3\\1&4\end{ytableau}}\ar[ur] & & {\begin{ytableau}1&4\\2&3\end{ytableau}}\ar[ul] & (1,0),(1,1),(1,2),(2,2) \\
& & {\begin{ytableau}2&4\\1&3\end{ytableau}}\ar[ul]\ar[ur] & (0,1),(1,1),(1,2),(2,2) \\
& & {\begin{ytableau}3&4\\1&2\end{ytableau}}\ar[u] & (0,1),(0,2),(1,2),(2,2)
}
\]
\end{example}

\begin{lemma}[Dominance lemma for tabloids]
\label{lemma:domtabloid}
If $k<l$ and $k$ appears in a lower row than $l$ in $\{t\}$, then $\{t\}\lhd (k,l)\{t\}$.
\end{lemma}

\begin{flushright}
\textit{Week 10, lecture 1 starts here}
\end{flushright}

\begin{proof}
Let $\lambda^i$ be the composition sequence of $\{t\}$ and $\mu^i$ that of $(k,l)\{t\}$. Then for $i<k$ and $i\geq l$ one has $\lambda^i=\mu^i$, so consider $k\leq i<l$. Let $r$ be the row of $\{t\}$ in which $k$ appears and $q$ be that of $\{t\}$ in which $l$ does. Note that $q<r$ by assumption. Then $\lambda^i=\mu^i$ with the $q$-th part decreased by 1 and $r$-th part increased by 1. Since $q<r$, one has $\lambda^i \lhd \mu^i$.
\end{proof}

\begin{defn}
For $v=\sum_i \alpha_i\{t_i\}\in M^\mu$, one says $\{t_i\}$ \textit{appears} in $v$ if $\alpha_i\neq 0$.
\end{defn}

\begin{coro}
If $t$ is standard and $\{s\}$ appears in $e_t$, then $\{t\}\unrhd\{s\}$.
\end{coro}
\begin{proof}
Let $s=\pi t$ for some $\pi\in C_t$ so $\{s\}$ appears in $e_t$. We prove by induction on number of pairs $k<l$ in the same column of $s$ such that $k$ is in a lower row than $l$. Such a pair is called a \textit{column inversion}. Given any such pair, Lemma \ref{lemma:domtabloid} implies $\{s\}\lhd (k,l)\{s\}$. But $(k,l)\{s\}$ has fewer column inversions than $\{s\}$: to prove this, note that only the entries between $k$ and $l$ must be considered, and for each of those, the number of inversions they are involved in cannot increase. Hence, by induction, $(k,l)\{s\}\unlhd\{t\}$.
\end{proof}

\begin{coro}
\label{coro:tismaxofet}
$\{t\}$ is the maximum tabloid that appears in $e_t$.
\end{coro}
\begin{defn}
Let $(A,\leq)$ be a poset. Then an element $b\in A$ is \underline{the} \textit{maximum} if $\forall c\in A,\ b\geq c$, and an element $b\in A$ is \underline{a} \textit{maximal element} if $\forall c\in A,\ b\not<c$. Minimum and minimality are defined analogously.
\end{defn}

\begin{prop}
The set $\{e_t:t\text{ is a standard }\lambda\text{-tableau}\}$ is linearly independent.
\end{prop}
\begin{proof}
Distinct standard tableaux $s\neq t$ have distinct tabloids $\{s\}\neq \{t\}$. By \ref{coro:tismaxofet}, $\{t\}$ is the maximum tabloid in $e_t$. Sort the standard $\lambda$-tableaux $t_1,\ldots,t_m$ so that $\{t_1\}$ is the maximal among the $\{t_i\}$. Hence, $\{t_1\}$ only appears in $e_{t_1}$ and not in any other $e_{t_i}$. Hence, every zero combination $\alpha_1e_{t_1}+\cdots+\alpha_me_{t_m}=0$ must have $\alpha_i=0$ because otherwise the coefficients for $\{t_1\}$ do not cancel. Remove $t_1$ from the list and continue inductively with the next maximal tabloid.
\end{proof}
It is also true that $\{e_t:t\text{ is a standard tableau}\}$ spans $S^\lambda$ but we will not prove it in class. A proof can be found in Sagan's book \textit{The symmetric group}, 2nd ed., Section 2.6. This proves Theorem \ref{thm:etsttisstandardisbasis}.

\begin{flushright}
\textit{Week 10, lecture 2 starts here}
\end{flushright}

\section{More examples}
\subsection{Alternating group $A_4$}
Recall $A_4=\{\pi\in S_4:\sgn(\pi)=1\}$, which is isomorphic to group of rotations $\R^3$ that stabilises a regular tetrahedron with barycentre the origin, and $|A_4|=12=|S_4|/2$.

Let $x=(1,2)(3,4),\ y=(1,3)(2,4),\ z=(1,4)(2,3)$ and $t=(1,2,3)$. Now $K:=\{\id,t,t^2\}$ is clearly a subgroup of $A_4$, but $H:=\{\id,x,y,z\}$ is as well since
\[
\label{G.1}
\tag{G.1}
xy=z=yx,\ xz=y=zx,\ yz=x=zy.
\]

Recall \ref{example:Snconjclas} and note that
\[
\label{G.2}
\tag{G.2}
txt^{-1}=z,\ tzt^{-1}=y,\ tyt^{-1}=x,
\]
and hence $H$ is normal.

Every element of $A_4$ can be written as $hk$ where $h\in H,k\in K$ by shifting via \ref{G.2}. The presentation is unique since $|H|\cdot |K|=|A_4|$.

\begin{claim}
The conjugacy classes in $A_4$ are $\{\id\},\ \{x,y,z\},\ \{t,tx,ty,tz\},\ \{t^2,t^2x,t^2y,t^2z\}$.
\end{claim}
\begin{proof}
Indeed all 4 sets are closed under conjugation with $t$ by \ref{G.2}. Similarly, conjugation with $x,y$ or $z$ does not change exponent of $t$ in the unique representation $hk$.

Define $s:H\rightarrow H:h\mapsto tht^{-1}$. Then $\forall i\in\{0,1,2\},\ s(t^ih)=t(t^ih)t^{-1}=t^itht^{-1}=t^i s(h)$ and $\forall i\in\{1,2\},\ xt^ix^{-1}=xt^ix=t^is^i(x)x=\left\{ \begin{aligned}
  ty \text{ if }i=1 \\ t^2z\text{ if }i=2
\end{aligned} \right..$
\end{proof}

For the 1-dimensional representations of $A_4$, let $\zeta=e^{2\pi i/3}$ and one obtains 3 non-isomorphic 1-dimensional irreducible characters of $A_4$ via $\forall h\in H,\ \chi_i(ht^j)=\zeta^{ij}$. Now $\chi_i:A_4\rightarrow GL_1(\C)$ is indeed a group homomorphism since the conversion to normed form $hk$ does not change the exponent of $t$, which implies
\[
\forall h_1,h_2\in H,\ \exists h\in H:\chi_i(h_1t^{j_1}h_2t^{j_2})=\chi_i(ht^{j_1+j_2})=\zeta^{i(j_1+j_2)}=\zeta^{ij_1}\zeta^{ij_2}=\chi_i(h_1t^{j_1})\chi_i(h_1t^{j_2}).
\]

Now by \ref{coro:nofpwniirfdisatmostnofconjclas} and \ref{lemma:sumirreddimsqisordG}, there must be one remaining 3-dimensional irreducible representation. One can try and check if $S^{3,1}\downarrow_{A_4}^{S_4}$ is irreducible: $\dim S^{(3,1)}=\# $ standard tableaux of shape $(3,1)$:
\[
\ytableausetup{notabloids}
\begin{ytableau}
1&2&3\\4
\end{ytableau},\begin{ytableau}
1&2&4\\3
\end{ytableau},\begin{ytableau}
1&3&4\\2
\end{ytableau}
\]
\begin{flushright}
\textit{Week 10, lecture 3 starts here}
\end{flushright}

Now
\[
\begin{aligned}
e_{\begin{ytableau}
1&3&4\\2
\end{ytableau}}&=\ytableausetup{tabloids}\begin{ytableau}
1&3&4\\2
\end{ytableau}-\begin{ytableau}
2&3&4\\1
\end{ytableau}\\ \ytableausetup{notabloids}
e_{\begin{ytableau}
1&2&4\\3
\end{ytableau}}&=\ytableausetup{tabloids}\begin{ytableau}
1&2&4\\3
\end{ytableau}-\begin{ytableau}
3&2&4\\1
\end{ytableau}=\begin{ytableau}
1&2&4\\3
\end{ytableau}-\begin{ytableau}
2&3&4\\1
\end{ytableau}\\ \ytableausetup{notabloids}
e_{\begin{ytableau}
1&2&3\\4
\end{ytableau}}&=\ytableausetup{tabloids}\begin{ytableau}
1&2&3\\4
\end{ytableau}-\begin{ytableau}
4&2&3\\1
\end{ytableau}=\begin{ytableau}
1&2&3\\4
\end{ytableau}-\begin{ytableau}
2&3&4\\1
\end{ytableau}
\end{aligned}
\]
so
\[
\begin{aligned}
\ytableausetup{notabloids}
xe_{\begin{ytableau}
1&3&4\\2
\end{ytableau}}&=e_{x\begin{ytableau}
1&3&4\\2
\end{ytableau}}=e_{\begin{ytableau}
2&4&3\\1
\end{ytableau}}=\ytableausetup{tabloids} \begin{ytableau}
2&4&3\\1
\end{ytableau}-\begin{ytableau}
1&4&3\\2
\end{ytableau}=\ytableausetup{notabloids} -e_{\begin{ytableau}
1&3&4\\2
\end{ytableau}}\\
xe_{\begin{ytableau}
1&2&4\\3
\end{ytableau}}&=e_{x\begin{ytableau}
1&2&4\\3
\end{ytableau}}=e_{\begin{ytableau}
2&1&3\\4
\end{ytableau}}=\ytableausetup{tabloids}\begin{ytableau}
2&1&3\\4
\end{ytableau}-\begin{ytableau}
4&1&3\\2
\end{ytableau}=\ytableausetup{notabloids} e_{\begin{ytableau}
1&2&3\\4
\end{ytableau}}-e_{\begin{ytableau}
1&3&4\\2
\end{ytableau}}\\
xe_{\begin{ytableau}
1&2&3\\4
\end{ytableau}}&=e_{x\begin{ytableau}
1&2&3\\4
\end{ytableau}}=e_{\begin{ytableau}
2&1&4\\3
\end{ytableau}}=\ytableausetup{tabloids}\begin{ytableau}
2&1&4\\3
\end{ytableau}-\begin{ytableau}
3&1&4\\2
\end{ytableau}=\ytableausetup{notabloids} e_{\begin{ytableau}
1&2&4\\3
\end{ytableau}}-e_{\begin{ytableau}
1&3&4\\2
\end{ytableau}}
\end{aligned}
\]
which gives us the representation matrix of $x$
\[
\begin{pmatrix}
-1 & -1 & -1 \\
0 & 0 & 1\\
0 & 1 & 0
\end{pmatrix}
\]
with respect to the basis
\[
e_{\begin{ytableau}
1&3&4\\2
\end{ytableau}},e_{\begin{ytableau}
1&2&4\\3
\end{ytableau}},e_{\begin{ytableau}
1&2&3\\4
\end{ytableau}}
\]
with trace $-1$. One continues and calculates $\psi=\chi_{(3,1)}\downarrow_{A_4}^{S_4}$:
\[
\psi(\id)=3,\quad \psi(x)=-1,\quad \psi(t)=0,\quad \psi(t^2)=0
\]
One verifies with Lemma \ref{lemma:irrediffinnerprod1} that $\psi$ is irreducible:
\[
\la\psi,\psi\ra=\frac{1}{12}(1\cdot 3^2+3\times(-1)^2+0)=1.
\]
The character table is
\begin{table}[H]
\centering
\begin{tabular}{c|cccc}
$A_4$    & $\id_{(1)}$ & $x_{(3)}$ & $t_{(4)}$ & $t^2_{(4)}$ \\ \hline
$\chi_0$ & 1           & 1         & 1         & 1           \\
$\chi_1$ & 1           & 1         & $\zeta$   & $\zeta^2$   \\
$\chi_2$ & 1           & 1         & $\zeta^2$ & $\zeta$     \\
$\psi$   & 3           & $-1$      & 0         & 0          
\end{tabular}
\end{table}

where $\zeta$ is the cubic root of unity.

\subsection{Dihedral group}
Recall that $D_{2n}=\la r,s\mid r^n=1,s^2=1,srs^{-1}=r^{-1}\ra$ and $|D_{2n}|=2n$. With the 1-dimensional representations $\phi:D_{2n}\rightarrow GL_1(\C)$,
\[
(\phi(r),\phi(s))\in\left\{\begin{aligned}
\{(1,1),(1,-1)\} &\qquad\text{if }n\text{ is odd}\\
\{(1,1),(1,-1),(-1,1),(-1,-1)\} &\qquad\text{if }n\text{ is even}
\end{aligned} \right.
\]

Let $\zeta=e^{2\pi i/n}$ and for $h\in\Z$ define the representation
\[
\begin{aligned}
\rho^h:D_{2n}&\rightarrow GL_2(\C)\\
r^k&\mapsto\begin{pmatrix}
\zeta^{hk}&0\\0&\zeta^{-hk}
\end{pmatrix}\\
sr^k&\mapsto\begin{pmatrix}
0 & \zeta^{hk}\\\zeta^{-hk}&0
\end{pmatrix}
\end{aligned}
\]
(Verify that $\rho^h=\rho_{\zeta^h}\uparrow_{C_n}^{D_n}$.)
\begin{claim}
For $0<h<\frac{n}{2},\ \rho^h$ is irreducible. (Check common eigenvectors of the two matrices.)
\end{claim}
The characters $\chi_h$ of $\rho^h$:
\[
\chi_h(r^k)=2\cos\frac{2\pi hk}{n},\qquad \chi_h(sr^k)=0
\]
Verify Lemma \ref{lemma:sumirreddimsqisordG}: if $n$ is even, 
\[
4\cdot 1^2+\left(\frac{n}{2}-1\right)\cdot 2^2=2n=|D_{2n}|,
\]
and if $n$ is odd
\[
2\cdot 1^2+\left(\frac{n-1}{2}\right)\cdot 2^2=2n=|D_{2n}|.
\]

\subsection{Quaternion group $Q_8$}
Recall that $Q_8=\la a,b\mid a^4=1,a^2=b^2,bab^{-1}=a^{-1}\ra$ and $|Q_8|=8$. We found (see HW2 Q1) that there are 4 1-dimensional representations and there is 1 2-dimensional representation
\[
\begin{aligned}
\phi:Q_8&\rightarrow GL_2(\C)\\
a&\mapsto\begin{pmatrix}
i&0\\0&-i
\end{pmatrix}\\
b&\mapsto\begin{pmatrix}
0&1\\-1&0
\end{pmatrix}
\end{aligned}
\]
The two matrices similarly have no common eigenvectors so the representation is irreducible. Applying \ref{lemma:sumirreddimsqisordG}:
\[
1\cdot 2^2+4\cdot 1^2=8=|Q_8|
\]
and as a corollary we get that there are 5 conjugacy classes in $Q_8$ for free; in fact the character table is
\begin{table}[H]
\centering
\begin{tabular}{c|ccccc}
$Q_8$          & $\id_{(1)}$ & $a_{(2)}$ & $ab_{(2)}$ & $b_{(2)}$ & $a^2_{(1)}$ \\ \hline
$\chi_{1,1}$   & 1           & 1         & 1          & 1         & 1           \\
$\chi_{1,-1}$  & 1           & 1         & $-1$       & $-1$      & 1           \\
$\chi_{-1,1}$  & 1           & $-1$      & $-1$       & 1         & 1           \\
$\chi_{-1,-1}$ & 1           & $-1$      & 1          & $-1$      & 1           \\
$\phi$         & 2           & 0         & 0          & 0         & $-2$       
\end{tabular}
\end{table}

\end{document}